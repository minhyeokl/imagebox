<html>

<head>
    <link href="book.css" rel="stylesheet" />
</head>
<div id="bookContainer">
    <div id="sbo-rt-content">
        <section data-type="chapter" epub:type="chapter"
            data-pdf-bookmark="Chapter 2. A Deep Dive into the GPT-4 and ChatGPT APIs">
            <div class="chapter" id="a_deep_dive_into_the_gpt_4_and_chatgpt_apis">
                <h1><span class="label">Chapter 2. </span>A Deep Dive into the GPT-4 and <span
                        class="keep-together">ChatGPT APIs</span></h1>
                <p>This chapter examines the GPT-4 and ChatGPT APIs in detail. The goal of this chapter is to give you a
                    solid understanding of the use of these APIs so that you can effectively integrate them into your
                    Python applications. By the end of this chapter, you will be well equipped to use these APIs and
                    exploit their powerful capabilities in your own development projects.</p>
                <p>We’ll start with an introduction to the OpenAI Playground. This will allow you to get a better
                    understanding of the models before writing any code. Next, we will look at the OpenAI Python
                    library. This includes the login information and a simple “Hello World” example. We will then cover
                    the process of creating and sending requests to the APIs. We will also look at how to manage API
                    responses. This will ensure that you know how to interpret the data returned by these APIs. In
                    addition, this chapter will cover considerations such as security best practices and cost
                    management.</p>
                <p>As we progress, you will gain practical knowledge that will be very useful in your journey as a
                    Python developer working with GPT-4 and ChatGPT. <a contenteditable="false" data-type="indexterm"
                        data-primary="Python" data-secondary="book code in GitHub repository" id="id416"></a><a
                        contenteditable="false" data-type="indexterm" data-primary="GitHub"
                        data-secondary="Python code in repository" id="id417"></a><a contenteditable="false"
                        data-type="indexterm" data-primary="resources online"
                        data-secondary="Python code in GitHub repository" id="id418"></a><a contenteditable="false"
                        data-type="indexterm" data-primary="scripting" data-secondary="Python code in GitHub repository"
                        id="id419"></a><a contenteditable="false" data-type="indexterm" data-primary="online resources"
                        data-see="resources online" id="id420"></a>All the Python code included in this chapter is
                    available in <a href="https://oreil.ly/DevAppsGPT_GitHub">the book’s GitHub repository</a>.</p>
                <div data-type="note" epub:type="note">
                    <h6>Note</h6>
                    <p>Before going any further, please<a contenteditable="false" data-type="indexterm"
                            data-primary="getting started" data-secondary="OpenAI account" id="id421"></a><a
                            contenteditable="false" data-type="indexterm" data-primary="OpenAI"
                            data-secondary="home page" id="id422"></a><a contenteditable="false" data-type="indexterm"
                            data-primary="home page of OpenAI" id="id423"></a><a contenteditable="false"
                            data-type="indexterm" data-primary="OpenAI" data-secondary="usage policies"
                            id="id424"></a><a contenteditable="false" data-type="indexterm"
                            data-primary="usage policies of OpenAI" id="id425"></a><a contenteditable="false"
                            data-type="indexterm" data-primary="OpenAI" data-secondary="account creation"
                            id="id426"></a><a contenteditable="false" data-type="indexterm"
                            data-primary="account creation for OpenAI" id="id427"></a><a contenteditable="false"
                            data-type="indexterm" data-primary="OpenAI" data-secondary="Terms and Policies"
                            id="id428"></a><a contenteditable="false" data-type="indexterm"
                            data-primary="Terms and Policies of OpenAI" id="id429"></a><a contenteditable="false"
                            data-type="indexterm" data-primary="Policies and Terms of OpenAI" id="id430"></a> check the
                        <a href="https://openai.com/policies/usage-policies">OpenAI usage policies</a>, and if you don’t
                        already have an account, create one on <a contenteditable="false" data-type="indexterm"
                            data-primary="resources online" data-secondary="OpenAI" data-tertiary="home page"
                            id="id431"></a>the <a href="https://openai.com">OpenAI home page</a>. You can also have a
                        look at the other legal documentation on the <a href="https://openai.com/policies">Terms and
                            Policies page</a>. The concepts introduced in <a data-type="xref"
                            href="ch01.html#gpt_4_and_chatgpt_essentials">Chapter&nbsp;1</a> are also essential for
                        using the OpenAI API and libraries. </p>
                </div>
                <section data-type="sect1" data-pdf-bookmark="Essential Concepts ">
                    <div class="sect1" id="essential_concepts">
                        <h1>Essential Concepts </h1>
                        <p>OpenAI offers several models<a contenteditable="false" data-type="indexterm"
                                data-primary="OpenAI" data-secondary="prices of models" id="id432"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="pricing OpenAI models"
                                data-secondary="about" id="id433"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="GPT models" data-secondary="pricing" id="id434"></a><a
                                contenteditable="false" data-type="indexterm"
                                data-primary="APIs (application programming interfaces)" data-secondary="prices"
                                data-see="pricing OpenAI models" id="id435"></a> that are designed for various tasks,
                            and each one has its own pricing. On the following pages, you will find a detailed
                            comparison of the available models and tips on how to choose which ones to use. It’s
                            important to note that the purpose for which a model was designed—whether for text
                            completion, chat, or editing—impacts how you would use its API. For instance, the models
                            behind ChatGPT and GPT-4 are chat based and use a chat endpoint. </p>
                        <p>The concept of prompts was introduced in <a data-type="xref"
                                href="ch01.html#gpt_4_and_chatgpt_essentials">Chapter&nbsp;1</a>. <a
                                contenteditable="false" data-type="indexterm" data-primary="prompts"
                                data-secondary="LLM entry points" id="id436"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="large language models (LLMs)"
                                data-secondary="prompts as entry points" data-seealso="prompt engineering"
                                id="id437"></a>Prompts are not specific to the OpenAI API but are the entry point for
                            all LLMs. Simply put, prompts are the input text that you send to the model, and they are
                            used to instruct the model on the specific task you want it to perform. For the ChatGPT and
                            GPT-4 models, prompts have a chat format, with the input and output messages stored in a
                            list. We will explore the details of this prompt format in this chapter.</p>
                        <p>The concept of tokens was also described in <a data-type="xref"
                                href="ch01.html#gpt_4_and_chatgpt_essentials">Chapter&nbsp;1</a>. <a
                                contenteditable="false" data-type="indexterm" data-primary="tokenization in GPT models"
                                data-secondary="tokens" id="id438"></a>Tokens are words or parts of words. <a
                                contenteditable="false" data-type="indexterm" data-primary="tokenization in GPT models"
                                data-secondary="tokens" data-tertiary="100 tokens as 75 English words" id="id439"></a>A
                            rough estimate is that 100 tokens equal approximately 75 words for an English text. <a
                                contenteditable="false" data-type="indexterm" data-primary="GPT models"
                                data-secondary="pricing" data-tertiary="tokens used" id="id440"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="pricing OpenAI models"
                                data-secondary="tokens used" id="id441"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="tokenization in GPT models" data-secondary="tokens"
                                data-tertiary="pricing based on number used" id="id442"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="models" data-see="GPT models" id="id443"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="OpenAI"
                                data-secondary="prices of models" data-tertiary="tokens used" id="id444"></a>Requests to
                            the OpenAI models are priced based on the number of tokens used: that is, the cost of a call
                            to the API depends on the length of both the input text and the output text. You will find
                            more details on managing and controlling the number of input and output tokens in <a
                                data-type="xref" href="#using_chatgpt_and_gpt_4">“Using ChatGPT and GPT-4”</a> and <a
                                data-type="xref" href="#using_other_text_completion_models">“Using Other Text Completion
                                Models”</a>. </p>
                        <p>These concepts are summarized in <a data-type="xref"
                                href="#fig_1_essential_concepts_for_using_the_openai_api">Figure&nbsp;2-1</a>.</p>
                        <figure>
                            <div id="fig_1_essential_concepts_for_using_the_openai_api" class="figure">
                                <img src="/api/v2/epubs/urn:orm:book:9781098152475/files/assets/dagc_0201.png" alt=""
                                    width="600" height="91">
                                <h6><span class="label">Figure 2-1. </span>Essential concepts for using the OpenAI API
                                </h6>
                            </div>
                        </figure>
                        <p>Now that we have discussed the concepts, let’s move on to the details of the models.</p>
                    </div>
                </section>
                <section data-type="sect1" data-pdf-bookmark="Models Available in the OpenAI API ">
                    <div class="sect1" id="models_available_in_the_openai_api">
                        <h1>Models Available in the OpenAI API </h1>
                        <p>The OpenAI API gives you access to <a href="https://platform.openai.com/docs/models">several
                                models developed by OpenAI</a>.<a contenteditable="false" data-type="indexterm"
                                data-primary="APIs (application programming interfaces)" data-secondary="OpenAI API"
                                data-tertiary="models available" id="ch02-modav"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="GPT models"
                                data-secondary="OpenAI API models available" id="ch02-modav2"></a><a
                                contenteditable="false" data-type="indexterm"
                                data-primary="large language models (LLMs)" data-secondary="OpenAI API models available"
                                id="ch02-modav3"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="OpenAI" data-secondary="API" data-tertiary="models available"
                                id="ch02-modav4"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="OpenAI" data-secondary="about GPT models" data-tertiary="models available"
                                id="ch02-modav5"></a> These models are available as a service over an API (through a
                            direct HTTP call or a provided library), meaning that OpenAI runs the models on distant
                            servers, and developers can simply send queries to them. </p>
                        <p>Each model comes with a different set of features and pricing. In this section, we will look
                            at the LLMs provided by OpenAI through its API. <a contenteditable="false"
                                data-type="indexterm" data-primary="GPT models"
                                data-secondary="OpenAI API models available" data-tertiary="proprietary"
                                id="id445"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="large language models (LLMs)" data-secondary="OpenAI API models available"
                                data-tertiary="proprietary" id="id446"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="APIs (application programming interfaces)"
                                data-secondary="OpenAI API" data-tertiary="models proprietary" id="id447"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="API"
                                data-tertiary="models proprietary" id="id448"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="OpenAI" data-secondary="about GPT models"
                                data-tertiary="proprietary" id="id449"></a>It is important to note that these models are
                            proprietary, so you cannot directly modify the code to adapt the models to your needs. But
                            as we will see later, you can fine-tune some of them on your specific data via the OpenAI
                            API. </p>
                        <div data-type="note" epub:type="note">
                            <h6>Note</h6>
                            <p>Some older OpenAI models,<a contenteditable="false" data-type="indexterm"
                                    data-primary="GPT-2 (OpenAI)" data-secondary="not proprietary" id="id450"></a><a
                                    contenteditable="false" data-type="indexterm" data-primary="GPT-2 (OpenAI)"
                                    data-secondary="download link" id="id451"></a><a contenteditable="false"
                                    data-type="indexterm" data-primary="resources online" data-secondary="OpenAI"
                                    data-tertiary="GPT-2 download" id="id452"></a><a contenteditable="false"
                                    data-type="indexterm" data-primary="APIs (application programming interfaces)"
                                    data-secondary="OpenAI API" data-tertiary="GPT-2 not proprietary or API accessible"
                                    data-seealso="GPT models" id="id453"></a><a contenteditable="false"
                                    data-type="indexterm" data-primary="OpenAI" data-secondary="API"
                                    data-tertiary="GPT-2 not proprietary or API accessible" data-seealso="GPT models"
                                    id="id454"></a><a contenteditable="false" data-type="indexterm"
                                    data-primary="GPT-2 (OpenAI)" data-secondary="not accessible via API"
                                    id="id455"></a> including the GPT-2 model, are not proprietary. While you can
                                download the GPT-2 model from <a href="https://oreil.ly/39Bu5">Hugging Face</a> or <a
                                    href="https://oreil.ly/CYPN6">GitHub</a>, you cannot access it through the API.</p>
                        </div>
                        <p>Since many of the models provided<a contenteditable="false" data-type="indexterm"
                                data-primary="APIs (application programming interfaces)" data-secondary="OpenAI API"
                                data-tertiary="models available updated list" id="id456"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="GPT models"
                                data-secondary="OpenAI API models available"
                                data-tertiary="models available updated list" id="id457"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="large language models (LLMs)"
                                data-secondary="OpenAI API models available"
                                data-tertiary="models available updated list" id="id458"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="OpenAI" data-secondary="about GPT models"
                                data-tertiary="models available updated list" id="id459"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="OpenAI" data-secondary="API"
                                data-tertiary="models available updated list" id="id460"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="resources online" data-secondary="OpenAI"
                                data-tertiary="API models available updated list" id="id461"></a> by OpenAI are
                            continually updated, it is difficult to give a complete list of them in this book; an
                            updated list of models that OpenAI provides is available in the <a
                                href="https://platform.openai.com/docs/models">online documentation</a>. Therefore, here
                            we will focus on the most important models:<a contenteditable="false" data-type="indexterm"
                                data-primary="pricing OpenAI models" data-secondary="about"
                                data-tertiary="models available" id="id462"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="GPT models" data-secondary="pricing"
                                id="id463"></a><a contenteditable="false" data-type="indexterm" data-primary="OpenAI"
                                data-secondary="prices of models" data-seealso="pricing OpenAI models" id="id464"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="InstructGPT"
                                id="id465"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="InstructGPT" data-secondary="pricing" id="id466"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)"
                                id="id467"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="ChatGPT (OpenAI)" data-secondary="pricing" id="id468"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="GPT-4 (OpenAI)"
                                id="id469"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="GPT-4 (OpenAI)" data-secondary="pricing" id="id470"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="GPT-3.5 (OpenAI)"
                                data-secondary="ChatGPT" data-seealso="ChatGPT" id="id471"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="ChatGPT (OpenAI)"
                                data-secondary="about" data-tertiary="GPT-3.5 Turbo" id="id472"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="GPT-3 (OpenAI)"
                                data-secondary="InstructGPT" id="id473"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="GPT-3 (OpenAI)" data-secondary="InstructGPT"
                                data-tertiary="pricing" id="id474"></a></p>
                        <dl>
                            <dt>InstructGPT</dt>
                            <dd>
                                <p>This family of models can process many single-turn completion tasks. The
                                    <code translate="no">text-ada-001</code> model is only capable of simple completion tasks but is
                                    also the fastest and least expensive model in the GPT-3 series. Both
                                    <code translate="no">text-babbage-001</code> and <code translate="no">text-curie-001</code> are a little more
                                    powerful but also more expensive. The <code translate="no">text-davinci-003</code> model can
                                    perform all completion tasks with excellent quality, but it is also the most
                                    expensive in the family of GPT-3 models.</p>
                            </dd>
                            <dt>ChatGPT </dt>
                            <dd>
                                <p>The model behind ChatGPT is <code translate="no">gpt-3.5-turbo</code>. As a chat model, it can take
                                    a series of messages as input and return an appropriately generated message as
                                    output. While the chat format of <code translate="no">gpt-3.5-turbo</code> is designed to
                                    facilitate multiturn conversations, it is also possible to use it for single-turn
                                    tasks without dialogue. In single-turn tasks, the performance of
                                    <code translate="no">gpt-3.5-turbo</code> is comparable to that of <code translate="no">text-davinci-003</code>,
                                    and since <code translate="no">gpt-3.5-turbo</code> is one-tenth the price, with more or less
                                    equivalent performance, it is recommended that you use it by default for single-turn
                                    tasks. The <code translate="no">gpt-3.5-turbo</code> model has a context size of 4,000 tokens,
                                    which means it can receive 4,000 tokens as input. OpenAI also provides another
                                    model, called <code translate="no">gpt-3.5-turbo-16k</code>, with the same capabilities as the
                                    standard <code translate="no">gpt-3.5-turbo</code> model but with four times the context size. </p>
                            </dd>
                            <dt>GPT-4 </dt>
                            <dd>
                                <p>This is the largest model released by OpenAI. It has also been trained on the most
                                    extensive multimodal corpus of text and images. As a result, it has knowledge and
                                    expertise in many domains. GPT-4 can follow complex natural language instructions
                                    and solve difficult problems accurately. It can be used for both chat and
                                    single-turn tasks with high accuracy. OpenAI offers two GPT-4 models:
                                    <code translate="no">gpt-4</code> has a context size of 8,000 tokens, and <code translate="no">gpt-4-32k</code>
                                    has a context size of 32,000 tokens. A context of 32,000 represents approximately
                                    24,000 words, which is a context of approximately 40 pages. </p>
                            </dd>
                        </dl>
                        <p>Both GPT-3.5 Turbo and GPT-4 are continually updated. When we refer to the models
                            <code translate="no">gpt-3.5-turbo</code>, <code translate="no">gpt-3.5-turbo-16k</code>, <code translate="no">gpt-4</code>, and
                            <code translate="no">gpt-4-32k</code>, we are referring to the latest version of these models. </p>
                        <p>Developers often need more stability and visibility into the LLM version they are using in
                            their applications. It can be difficult for developers to use model languages in which
                            versions can change from one night to the next and can behave differently for the same input
                            prompt. For this purpose, static snapshot versions of these models are also available. At
                            the time of this writing, the most recent snapshot versions were
                            <code translate="no">gpt-3.5-turbo-0613</code>, <code translate="no">gpt-3.5-turbo-16k-0613</code>,
                            <code translate="no">gpt-4-0613</code>, and <code translate="no">gpt-4-32k-0613</code>. </p>
                        <p>As discussed in <a data-type="xref"
                                href="ch01.html#gpt_4_and_chatgpt_essentials">Chapter&nbsp;1</a>, OpenAI recommends<a
                                contenteditable="false" data-type="indexterm" data-primary="InstructGPT"
                                data-secondary="use instead of GPT-3" id="id475"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="GPT-3 (OpenAI)" data-secondary="InstructGPT"
                                data-tertiary="use instead of GPT-3" id="id476"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="davinci available in API" id="id477"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="curie available in API"
                                id="id478"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="available in API" id="id479"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="ada available in API" id="id480"></a> using the
                            InstructGPT series rather than the original GPT-3–based models. These models are still
                            available in the API under the names <code translate="no">davinci</code>, <code translate="no">curie</code>,
                            <code translate="no">babbage</code>, and <code translate="no">ada</code>. Given that these models can provide strange,
                            false, and misleading answers, as seen in <a data-type="xref"
                                href="ch01.html#gpt_4_and_chatgpt_essentials">Chapter&nbsp;1</a>, caution in their use
                            is advised. However, these models are still used because they are the only ones that can be
                            fine-tuned to your data. <a contenteditable="false" data-type="indexterm"
                                data-primary="fine-tuning a model" data-secondary="GPT-3.5 Turbo" id="id481"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="fine-tuning a model"
                                data-secondary="GPT-4" id="id482"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="GPT-4 (OpenAI)" data-secondary="fine-tuning availability"
                                id="id483"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="GPT-3.5 (OpenAI)" data-secondary="fine-tuning availability"
                                id="id484"></a>At the time of this writing, OpenAI has announced that fine-tuning for
                            GPT-3.5 Turbo and GPT-4 will be available in 2024.</p>
                        <div data-type="note" epub:type="note">
                            <h6>Note</h6>
                            <p>The SFT model (presented in <a data-type="xref"
                                    href="ch01.html#gpt_4_and_chatgpt_essentials">Chapter&nbsp;1</a>) obtained<a
                                    contenteditable="false" data-type="indexterm"
                                    data-primary="SFT (supervised fine-tuning) model"
                                    data-secondary="davinci-instruct-beta API access" id="id485"></a><a
                                    contenteditable="false" data-type="indexterm"
                                    data-primary="davinci-instruct-beta model via API" id="id486"></a><a
                                    contenteditable="false" data-type="indexterm"
                                    data-primary="supervised fine-tuning (SFT) model"
                                    data-secondary="davinci-instruct-beta API access" id="id487"></a> after the
                                supervised fine-tuning stage, which did not go through the RLHF stage, is also available
                                in the API under the name <code translate="no">davinci-instruct-beta</code>.<a contenteditable="false"
                                    data-type="indexterm" data-primary="" data-startref="ch02-modav" id="id488"></a><a
                                    contenteditable="false" data-type="indexterm" data-primary=""
                                    data-startref="ch02-modav2" id="id489"></a><a contenteditable="false"
                                    data-type="indexterm" data-primary="" data-startref="ch02-modav3" id="id490"></a><a
                                    contenteditable="false" data-type="indexterm" data-primary=""
                                    data-startref="ch02-modav4" id="id491"></a><a contenteditable="false"
                                    data-type="indexterm" data-primary="" data-startref="ch02-modav5" id="id492"></a>
                            </p>
                        </div>
                    </div>
                </section>
                <section data-type="sect1" data-pdf-bookmark="Trying GPT Models with the OpenAI Playground">
                    <div class="sect1" id="trying_gpt_models_with_the_openai_playground">
                        <h1>Trying GPT Models with the OpenAI Playground</h1>
                        <p>An excellent way to test the different<a contenteditable="false" data-type="indexterm"
                                data-primary="GPT models" data-secondary="OpenAI Playground"
                                data-seealso="OpenAI Playground" id="ch02plag"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="OpenAI Playground" id="ch02plag2"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="OpenAI"
                                data-secondary="Playground" data-see="OpenAI Playground" id="id493"></a><a
                                contenteditable="false" data-type="indexterm"
                                data-primary="large language models (LLMs)" data-secondary="OpenAI Playground"
                                data-seealso="OpenAI Playground" id="ch02plag4"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="APIs (application programming interfaces)"
                                data-secondary="Playground" data-see="OpenAI Playground" id="id494"></a> language models
                            provided by OpenAI directly, without coding, is to use the OpenAI Playground, a web-based
                            platform that allows you to quickly test the various LLMs provided by OpenAI on specific
                            tasks. The Playground lets you write prompts, select the model, and easily see the output
                            that is generated.<a contenteditable="false" data-type="indexterm"
                                data-primary="getting started" data-secondary="OpenAI account"
                                data-tertiary="Playground access" id="id495"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="pricing OpenAI models" data-secondary="Playground"
                                data-tertiary="means of payment at sign-up" id="id496"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="OpenAI Playground" data-secondary="paying for"
                                data-tertiary="means of payment at sign-up" id="id497"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="account creation for OpenAI"
                                data-secondary="Playground access" id="id498"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="OpenAI" data-secondary="account creation"
                                data-tertiary="Playground access" id="id499"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="resources online" data-secondary="OpenAI"
                                data-tertiary="Playground" id="id500"></a> </p>
                        <p>Here’s how to access the Playground:</p>
                        <ol>
                            <li>
                                <p>Navigate to the <a href="https://openai.com">OpenAI home page</a> and click
                                    Developers, then Overview.</p>
                            </li>
                            <li>
                                <p>If you already have an account and are not logged in, click Login at the upper right
                                    of the screen. If you don’t have an account with OpenAI, you will need to create one
                                    in order to use the Playground and most of the OpenAI features. Click Sign Up at the
                                    upper right of the screen. Note that because there is a charge for the Playground
                                    and the API, you will need to provide a means of payment.</p>
                            </li>
                            <li>
                                <p>Once you are logged in, you will see the link to join the Playground at the upper
                                    left of the web page. Click the link, and you should see something similar to <a
                                        data-type="xref"
                                        href="#fig_2_the_openai_playground_interface_in_text_completion">Figure&nbsp;2-2</a>.
                                </p>
                            </li>
                        </ol>
                        <figure>
                            <div id="fig_2_the_openai_playground_interface_in_text_completion" class="figure">
                                <img src="/api/v2/epubs/urn:orm:book:9781098152475/files/assets/dagc_0202.png" alt=""
                                    width="600" height="601">
                                <h6><span class="label">Figure 2-2. </span>The OpenAI Playground interface in Text
                                    Completion mode</h6>
                            </div>
                        </figure>
                        <div data-type="note" epub:type="note">
                            <h6>Note</h6>
                            <p>The ChatGPT Plus option is<a contenteditable="false" data-type="indexterm"
                                    data-primary="ChatGPT (OpenAI)" data-secondary="pricing"
                                    data-tertiary="Plus option independent of API or Playground" id="id501"></a><a
                                    contenteditable="false" data-type="indexterm" data-primary="pricing OpenAI models"
                                    data-secondary="ChatGPT Plus option independent of API or Playground"
                                    id="id502"></a> independent of using the API or the Playground. If you have
                                subscribed to the ChatGPT Plus service, you will still be charged for using the API and
                                the Playground.</p>
                        </div>
                        <p class="pagebreak-before less_space">The main whitespace in the center<a
                                contenteditable="false" data-type="indexterm" data-primary="OpenAI Playground"
                                data-secondary="interface" id="ch02-inf"></a> of the interface is for your input
                            message. After writing your message, click Submit to generate a completion to your message.
                            In the example in <a data-type="xref"
                                href="#fig_2_the_openai_playground_interface_in_text_completion">Figure&nbsp;2-2</a>, we
                            wrote “As Descartes said, I think therefore”, and after we clicked Submit, the model
                            completed our input with “I am”. </p>
                        <div data-type="warning" epub:type="warning">
                            <h6>Warning</h6>
                            <p>Every time you click Submit, <a contenteditable="false" data-type="indexterm"
                                    data-primary="pricing OpenAI models" data-secondary="Playground"
                                    data-tertiary="Submit click billing account" id="id503"></a><a
                                    contenteditable="false" data-type="indexterm" data-primary="OpenAI Playground"
                                    data-secondary="paying for" data-tertiary="Submit click billing account"
                                    id="id504"></a><a contenteditable="false" data-type="indexterm"
                                    data-primary="OpenAI Playground" data-secondary="paying for"
                                    data-tertiary="cost of text completion example" id="id505"></a><a
                                    contenteditable="false" data-type="indexterm" data-primary="pricing OpenAI models"
                                    data-secondary="Playground" data-tertiary="cost of text completion example"
                                    id="id506"></a>your OpenAI account is billed for the usage. We give more information
                                on prices later in this chapter, but as an example, this completion cost almost $0.0002.
                            </p>
                        </div>
                        <p>There are many options around the sides of the interface. Let’s start at the bottom. To the
                            right of the Submit button is an undo button [labeled (A) in the figure] that deletes the
                            last generated text. In our case, it will delete “I am”. Next is the regenerate button
                            [labeled (B) in the figure], which regenerates text that was just deleted. This is followed
                            by the history button [labeled (C)], which contains all your requests from the previous 30
                            days. Note that once you are in the history menu, it is easy to delete requests if necessary
                            for privacy reasons.</p>
                        <p>The options panel on the right side of the screen provides various settings related to the
                            interface and the chosen model. We will only explain some of these options here; others will
                            be covered later in the book. The first drop-down list on the right is the Mode list
                            [labeled (D)]. At the time of this writing, the available modes are Chat (default),
                            Complete, and Edit. </p>
                        <div data-type="note" epub:type="note">
                            <h6>Note</h6>
                            <p>Complete and Edit modes are marked as legacy at the time of this book’s writing and will
                                probably disappear in January 2024. </p>
                        </div>
                        <p>As demonstrated previously, the language model strives to complete the user’s input prompt
                            seamlessly in the Playground’s default mode.</p>
                        <p><a data-type="xref"
                                href="#fig_3_the_openai_playground_interface_in_chat_mode">Figure&nbsp;2-3</a> shows<a
                                contenteditable="false" data-type="indexterm" data-primary="OpenAI Playground"
                                data-secondary="interface" data-tertiary="chat mode" id="id507"></a> an example of using
                            the Playground in Chat mode. On the left of the screen is the System pane [labeled (E)].
                            Here you can describe how the chat system should behave. For instance, in <a
                                data-type="xref"
                                href="#fig_3_the_openai_playground_interface_in_chat_mode">Figure&nbsp;2-3</a>, we asked
                            it to be a helpful assistant who loves cats. We also asked it to only talk about cats and to
                            give short answers. The dialogue that results from having set these parameters is displayed
                            in the center of the screen. </p>
                        <p>If you want to continue the dialogue with the system, click “Add message” [(F)], enter your
                            message, and click Submit [(G)]. It is also possible to define the model on the right [(H)];
                            here we use GPT-4. Note that not all models are available in all modes. For instance, only
                            GPT-4 and GPT-3.5 Turbo are available in Chat mode. </p>
                        <figure>
                            <div id="fig_3_the_openai_playground_interface_in_chat_mode" class="figure">
                                <img src="/api/v2/epubs/urn:orm:book:9781098152475/files/assets/dagc_0203.png" alt=""
                                    width="600" height="366">
                                <h6><span class="label">Figure 2-3. </span>The OpenAI Playground interface in Chat mode
                                </h6>
                            </div>
                        </figure>
                        <p>Another mode available in the<a contenteditable="false" data-type="indexterm"
                                data-primary="OpenAI Playground" data-secondary="interface" data-tertiary="edit mode"
                                id="id508"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="Playground" data-see="OpenAI Playground" id="id509"></a> Playground is
                            Edit. In this mode, shown in <a data-type="xref"
                                href="#fig_4_the_openai_playground_interface_in_edit_mode">Figure&nbsp;2-4</a>, you
                            provide some text [(I)] and instruction [(J)], and the model will attempt to modify the text
                            accordingly. In this example, a text describing a young man who is going on a trip is given.
                            The model is instructed to change the subject of the text to an old woman, and you can see
                            that the result respects the instructions [(K)].</p>
                        <figure>
                            <div id="fig_4_the_openai_playground_interface_in_edit_mode" class="figure">
                                <img src="/api/v2/epubs/urn:orm:book:9781098152475/files/assets/dagc_0204.png" alt=""
                                    width="600" height="216">
                                <h6><span class="label">Figure 2-4. </span>The OpenAI Playground interface in Edit mode
                                </h6>
                            </div>
                        </figure>
                        <p>On the right side of the Playground interface, below the Mode drop-down list, is the Model
                            drop-down list [(L)]. As you have already seen, this is where you choose the LLM. The models
                            available in the drop-down list depend on the selected mode. Below the Model drop-down list
                            are parameters, such as Temperature [(M)], that define the model’s behavior. We will not go
                            into the details of these parameters here. Most of them will be explored when we closely
                            examine how these different models work. </p>
                        <p>At the top of the screen<a contenteditable="false" data-type="indexterm"
                                data-primary="OpenAI Playground" data-secondary="interface" data-tertiary="presets"
                                id="id510"></a><a contenteditable="false" data-type="indexterm" data-primary="prompts"
                                data-secondary="presets in OpenAI Playground" id="id511"></a> is the “Load a preset”
                            drop-down list [(N)] and four buttons. In <a data-type="xref"
                                href="#fig_2_the_openai_playground_interface_in_text_completion">Figure&nbsp;2-2</a>, we
                            used the LLM to complete the sentence “As Descartes said, I think therefore”, but it is
                            possible to make the model perform particular tasks by using appropriate prompts. <a
                                data-type="xref" href="#fig_5_drop_down_list_of_examples">Figure&nbsp;2-5</a> shows a
                            list of common tasks the model can perform associated with an example of a preset. </p>
                        <figure>
                            <div id="fig_5_drop_down_list_of_examples" class="figure">
                                <img src="/api/v2/epubs/urn:orm:book:9781098152475/files/assets/dagc_0205.png" alt=""
                                    width="600" height="679">
                                <h6><span class="label">Figure 2-5. </span>Drop-down list of examples</h6>
                            </div>
                        </figure>
                        <p>It should be noted that the proposed presets define not only the prompt but also some options
                            on the right side of the screen. For example, if you click Grammatical Standard English, you
                            will see in the main window the prompt displayed in <a data-type="xref"
                                href="#fig_6_example_prompt_for_grammatical_standard_english">Figure&nbsp;2-6</a>.</p>
                        <figure>
                            <div id="fig_6_example_prompt_for_grammatical_standard_english" class="figure">
                                <img src="/api/v2/epubs/urn:orm:book:9781098152475/files/assets/dagc_0206.png" alt=""
                                    width="600" height="153">
                                <h6><span class="label">Figure 2-6. </span>Example prompt for Grammatical Standard
                                    English</h6>
                            </div>
                        </figure>
                        <p>If you click Submit, you will obtain the following response: “She did not go to the market.”
                            <a contenteditable="false" data-type="indexterm" data-primary="prompts"
                                data-secondary="presets in OpenAI Playground"
                                data-tertiary="complete list of examples link" id="id512"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="resources online" data-secondary="OpenAI"
                                data-tertiary="Playground example prompts" id="id513"></a>You can use the prompts
                            proposed in the drop-down list as a starting point, but you will always have to modify them
                            to fit your problem. OpenAI also provides a <a
                                href="https://platform.openai.com/examples">complete list of examples</a> for different
                            tasks. </p>
                        <p>Next to the “Load a preset” drop-down list in <a data-type="xref"
                                href="#fig_4_the_openai_playground_interface_in_edit_mode">Figure&nbsp;2-4</a> is the
                            Save button [(O)]. Imagine that you have defined a valuable prompt with a model and its
                            parameter for your task, and you want to easily reuse it later in the Playground. This Save
                            button will save the current state of the Playground as a preset. You can give your preset a
                            name and a description, and once saved, your preset will appear in the “Load a preset”
                            drop-down list.</p>
                        <p>The second-to-last button<a contenteditable="false" data-type="indexterm"
                                data-primary="OpenAI Playground" data-secondary="interface"
                                data-tertiary="code to run test in a script" id="id514"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="Python" data-secondary="OpenAI Playground test code"
                                id="id515"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="Node.js code for OpenAI Playground test" id="id516"></a><a
                                contenteditable="false" data-type="indexterm"
                                data-primary="cURL code for OpenAI Playground test" id="id517"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="scripting"
                                data-secondary="OpenAI Playground test code for" id="id518"></a> at the top of the
                            interface is called “View code” [(P)]. It gives the code to run your test in the Playground
                            directly in a script. You can request code in Python, Node.js, or cURL to interact directly
                            with the OpenAI remote server in a Linux terminal. If the Python code of our example “As
                            Descartes said, I think therefore” is asked, we get the following:<a contenteditable="false"
                                data-type="indexterm" data-primary="max_tokens input parameter for chat completion"
                                data-secondary="Playground text completion example" id="id519"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="parameters"
                                data-secondary="max_tokens input parameter"
                                data-tertiary="Playground text completion example" id="id520"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="openai.Completion.create()"
                                id="id521"></a></p>

                        <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="kn">import</code> <code translate="no" class="nn">openai</code>
  <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">api_key</code> <code translate="no" class="o">=</code> <code translate="no" class="n">os</code><code translate="no" class="o">.</code><code translate="no" class="n">getenv</code><code translate="no" class="p">(</code><code translate="no" class="s2">"OPENAI_API_KEY"</code><code translate="no" class="p">)</code>
  <code translate="no" class="n">response</code> <code translate="no" class="o">=</code> <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">Completion</code><code translate="no" class="o">.</code><code translate="no" class="n">create</code><code translate="no" class="p">(</code>
      <code translate="no" class="n">model</code><code translate="no" class="o">=</code><code translate="no" class="s2">"text-davinci-003"</code><code translate="no" class="p">,</code>
      <code translate="no" class="n">prompt</code><code translate="no" class="o">=</code><code translate="no" class="s2">"As Descartes said, I think therefore"</code><code translate="no" class="p">,</code>
      <code translate="no" class="n">temperature</code><code translate="no" class="o">=</code><code translate="no" class="mf">0.7</code><code translate="no" class="p">,</code>
      <code translate="no" class="n">max_tokens</code><code translate="no" class="o">=</code><code translate="no" class="mi">3</code><code translate="no" class="p">,</code>
      <code translate="no" class="n">top_p</code><code translate="no" class="o">=</code><code translate="no" class="mi">1</code><code translate="no" class="p">,</code>
      <code translate="no" class="n">frequency_penalty</code><code translate="no" class="o">=</code><code translate="no" class="mi">0</code><code translate="no" class="p">,</code>
      <code translate="no" class="n">presence_penalty</code><code translate="no" class="o">=</code><code translate="no" class="mi">0</code><code translate="no" class="p">,</code>
  <code translate="no" class="p">)</code></pre>

                        <p>Now that you understand how to use the Playground to test OpenAI language models without
                            coding, let’s discuss how to obtain and manage your API keys for OpenAI services.<a
                                contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch02plag"
                                id="id522"></a><a contenteditable="false" data-type="indexterm" data-primary=""
                                data-startref="ch02plag2" id="id523"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="" data-startref="ch02plag4" id="id524"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch02-inf"
                                id="id525"></a></p>
                    </div>
                </section>
                <section data-type="sect1" data-pdf-bookmark="Getting Started: The OpenAI Python Library">
                    <div class="sect1" id="getting_started_the_openai_python_library">
                        <h1>Getting Started: The OpenAI Python Library</h1>
                        <p>In this section, we’ll focus<a contenteditable="false" data-type="indexterm"
                                data-primary="getting started" data-secondary="OpenAI Python library"
                                id="ch02pylib"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="Python" data-secondary="OpenAI Python library"
                                data-tertiary="OpenAI API key in script" id="ch02pylib2"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="scripting"
                                data-secondary="OpenAI API key in Python script" id="ch02pylib3"></a><a
                                contenteditable="false" data-type="indexterm"
                                data-primary="APIs (application programming interfaces)" data-secondary="OpenAI API"
                                data-tertiary="key in Python script" id="ch02pylib4"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="OpenAI Playground" data-secondary="OpenAI API"
                                data-tertiary="key in Python script" id="ch02pylib5"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="OpenAI" data-secondary="API"
                                data-tertiary="key in Python script" id="ch02pylib6"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="key for API access"
                                data-secondary="in Python script" data-secondary-sortas="Python script"
                                id="ch02pylib7"></a> on how to use API keys in a small Python script, and we’ll perform
                            our first test with this OpenAI API.</p>
                        <p>OpenAI provides GPT-4 and ChatGPT as<a contenteditable="false" data-type="indexterm"
                                data-primary="GPT-4 (OpenAI)" data-secondary="about GPT models"
                                data-tertiary="provided as a service" id="id526"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="about"
                                data-tertiary="provided as a service" id="id527"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="getting started" data-secondary="OpenAI account"
                                data-tertiary="scripts calling GPT-4 and ChatGPT" id="id528"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="account creation for OpenAI"
                                data-secondary="scripts calling GPT-4 and ChatGPT" id="id529"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="OpenAI"
                                data-secondary="account creation" data-tertiary="scripts calling GPT-4 and ChatGPT"
                                id="id530"></a> a service. This means users cannot have direct access to the models’
                            code and cannot run the models on their own servers. However, OpenAI manages the deployment
                            and running of its models, and users can call these models as long as they have an account
                            and a secret key. </p>
                        <p>Before completing the following steps, make sure you are logged in on the <a
                                href="https://platform.openai.com/login?launch">OpenAI web page</a>.</p>
                        <section data-type="sect2" data-pdf-bookmark="OpenAI Access and API Key">
                            <div class="sect2" id="openai_access_and_api_key">
                                <h2>OpenAI Access and API Key</h2>
                                <p>OpenAI requires you to have<a contenteditable="false" data-type="indexterm"
                                        data-primary="APIs (application programming interfaces)"
                                        data-secondary="OpenAI API" data-tertiary="key to use services"
                                        id="id531"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="OpenAI Playground" data-secondary="OpenAI API"
                                        data-tertiary="key to use services" id="id532"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="key for API access"
                                        data-secondary="key to use services" id="id533"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="OpenAI" data-secondary="API"
                                        data-tertiary="key to use services" id="id534"></a> an API key to use its
                                    services. This key has two purposes:</p>
                                <ul>
                                    <li>It gives you the right to call the API methods.</li>
                                    <li>It links your API calls to your account for billing purposes.</li>
                                </ul>
                                <p>You must have this key in order to call the OpenAI services from your application.
                                </p>
                                <p>To obtain the key, navigate to the <a href="https://platform.openai.com">OpenAI
                                        platform</a> page. In the upper-right corner, click your account name and then
                                    “View API keys,” as shown in <a data-type="xref"
                                        href="#fig_7_openai_menu_to_select_view_api_keys">Figure&nbsp;2-7</a>.</p>
                                <figure>
                                    <div id="fig_7_openai_menu_to_select_view_api_keys" class="figure">
                                        <img src="/api/v2/epubs/urn:orm:book:9781098152475/files/assets/dagc_0207.png"
                                            alt="" width="600" height="716">
                                        <h6><span class="label">Figure 2-7. </span>OpenAI menu to select “View API keys”
                                        </h6>
                                    </div>
                                </figure>
                                <p>When you are on the “API keys” page, click “Create new secret key” and make a copy of
                                    your key. This key is a long string of characters starting with <em>sk-</em>. </p>
                                <div data-type="warning" epub:type="warning">
                                    <h6>Warning</h6>
                                    <p>Keep this key safe and secure because it is directly linked to your account, and
                                        a stolen key could result in unwanted costs.</p>
                                </div>
                                <p>Once you have your key,<a contenteditable="false" data-type="indexterm"
                                        data-primary="APIs (application programming interfaces)"
                                        data-secondary="OpenAI API" data-tertiary="key exported as environment variable"
                                        id="id535"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="OpenAI" data-secondary="API"
                                        data-tertiary="key exported as environment variable" id="id536"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="OpenAI Playground"
                                        data-secondary="OpenAI API" data-tertiary="key exported as environment variable"
                                        id="id537"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="key for API access"
                                        data-secondary="exported as environment variable" id="id538"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="environment variable holding API key" id="id539"></a> the best
                                    practice is to export it as an environment variable. This will allow your
                                    application to access the key without writing it directly in your code. Here is how
                                    to do that.</p>
                                <p class="pagebreak-before less_space">For Linux or Mac:</p>

                                <pre translate="no" data-type="programlisting"># set environment variable OPENAI_API_KEY for current session
  export OPENAI_API_KEY=sk-(...)
  # check that environment variable was set
  echo $OPENAI_API_KEY</pre>

                                <p>For Windows:</p>

                                <pre translate="no" data-type="programlisting"># set environment variable OPENAI_API_KEY for current session
  set OPENAI_API_KEY=sk-(...)
  # check that environment variable was set
  echo %OPENAI_API_KEY%</pre>

                                <p>The preceding code snippets will set an environment variable and make your key
                                    available to other processes that are launched from the same shell session. For
                                    Linux systems, it is also possible to add this code directly to your
                                    <em>.bashrc</em> file. This will allow access to your environment variable in all
                                    your shell sessions. Of course, do not include these command lines in the code you
                                    push to a public repository.</p>
                                <p>To permanently add/change an environment variable in Windows 11, press the Windows
                                    key + R key simultaneously to open the Run Program Or File window. In this window,
                                    type <strong>sysdm.cpl</strong> to go to the System Properties panel. Then click the
                                    Advanced tab followed by the Environment Variables button. On the resulting screen,
                                    you can add a new environment variable with your OpenAI key.</p>
                                <div data-type="tip">
                                    <h6>Tip</h6>
                                    <p>OpenAI provides a detailed <a href="https://oreil.ly/2Qobg">page on API key
                                            safety</a>.</p>
                                </div>
                                <p>Now that you have your key, it’s time to write your first “Hello World” program with
                                    the OpenAI API.</p>
                            </div>
                        </section>
                        <section data-type="sect2" data-pdf-bookmark="“Hello World” Example ">
                            <div class="sect2" id="_hello_world_example">
                                <h2>“Hello World” Example </h2>
                                <p>This section shows the first<a contenteditable="false" data-type="indexterm"
                                        data-primary="Python" data-secondary="OpenAI Python library"
                                        data-tertiary="Hello world" id="id540"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="OpenAI" data-secondary="API"
                                        data-tertiary="Hello world example" id="id541"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="APIs (application programming interfaces)"
                                        data-secondary="OpenAI API" data-tertiary="Hello world example"
                                        id="id542"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="Hello world example Python code" id="id543"></a> lines of code
                                    with the OpenAI Python library. We will start with a classic “Hello World” example
                                    to understand how OpenAI provides its services.</p>
                                <p>Install the Python library with <em>pip</em>:<a contenteditable="false"
                                        data-type="indexterm" data-primary="Python"
                                        data-secondary="OpenAI Python library" data-tertiary="installing with pip"
                                        id="id544"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="pip" data-secondary="installing OpenAI Python library"
                                        id="id545"></a></p>

                                <pre translate="no" data-type="programlisting">pip install openai</pre>

                                <p>Next, access the OpenAI API in Python:</p>

                                <pre translate="no" data-type="programlisting"
                                    data-code-language="python"><code translate="no" class="kn">import</code> <code translate="no" class="nn">openai</code>
  <code translate="no" class="c1"># Call the openai ChatCompletion endpoint</code>
  <code translate="no" class="n">response</code> <code translate="no" class="o">=</code> <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">ChatCompletion</code><code translate="no" class="o">.</code><code translate="no" class="n">create</code><code translate="no" class="p">(</code>
      <code translate="no" class="n">model</code><code translate="no" class="o">=</code><code translate="no" class="s2">"gpt-3.5-turbo"</code><code translate="no" class="p">,</code>
      <code translate="no" class="n">messages</code><code translate="no" class="o">=</code><code translate="no" class="p">[{</code><code translate="no" class="s2">"role"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"user"</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"content"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"Hello World!"</code><code translate="no" class="p">}],</code>
  <code translate="no" class="p">)</code>
  <code translate="no" class="c1"># Extract the response</code>
  <code translate="no" class="nb">print</code><code translate="no" class="p">(</code><code translate="no" class="n">response</code><code translate="no" class="p">[</code><code translate="no" class="s2">"choices"</code><code translate="no" class="p">][</code><code translate="no" class="mi">0</code><code translate="no" class="p">][</code><code translate="no" class="s2">"message"</code><code translate="no" class="p">][</code><code translate="no" class="s2">"content"</code><code translate="no" class="p">])</code></pre>

                                <p>You will see the following output:</p>

                                <pre translate="no" data-type="programlisting">Hello there! How may I assist you today?</pre>

                                <p>Congratulations! You just wrote your first program using the OpenAI Python library.
                                </p>
                                <p>Let’s go through the details of using this library.<a contenteditable="false"
                                        data-type="indexterm" data-primary="Python"
                                        data-secondary="OpenAI Python library" data-tertiary="details of using"
                                        id="id546"></a> </p>
                                <div data-type="tip">
                                    <h6>Tip</h6>
                                    <p>The OpenAI Python library<a contenteditable="false" data-type="indexterm"
                                            data-primary="Python" data-secondary="OpenAI Python library"
                                            data-tertiary="command-line utility" id="id547"></a><a
                                            contenteditable="false" data-type="indexterm"
                                            data-primary="command-line utility of OpenAI Python library"
                                            id="id548"></a><a contenteditable="false" data-type="indexterm"
                                            data-primary="Hello world example Python code"
                                            data-secondary="command-line utility" id="id549"></a><a
                                            contenteditable="false" data-type="indexterm"
                                            data-primary="APIs (application programming interfaces)"
                                            data-secondary="OpenAI API" data-tertiary="Hello world example"
                                            id="id550"></a><a contenteditable="false" data-type="indexterm"
                                            data-primary="OpenAI" data-secondary="API"
                                            data-tertiary="Hello world example" id="id551"></a> also provides a
                                        command-line utility. The following code, running in a terminal, is equivalent
                                        to executing the previous “Hello World” example:<a contenteditable="false"
                                            data-type="indexterm" data-primary="openai api chat_completion.create"
                                            id="id552"></a><a contenteditable="false" data-type="indexterm"
                                            data-primary="chat_completion from command line" id="id553"></a> </p>
                                    <pre translate="no" data-type="programlisting">openai api chat_completions.create -m gpt-3.5-turbo \
      -g user "Hello world"</pre>
                                    <p>It is also possible to interact<a contenteditable="false" data-type="indexterm"
                                            data-primary="OpenAI" data-secondary="API"
                                            data-tertiary="interaction pathways" id="id554"></a><a
                                            contenteditable="false" data-type="indexterm"
                                            data-primary="APIs (application programming interfaces)"
                                            data-secondary="OpenAI API" data-tertiary="interaction pathways"
                                            id="id555"></a> with the OpenAI API through HTTP requests or the official
                                        Node.js library, as well as other <a
                                            href="https://platform.openai.com/docs/libraries">community-maintained
                                            libraries</a>.</p>
                                </div>
                                <p>As you may have observed,<a contenteditable="false" data-type="indexterm"
                                        data-primary="environment variable holding API key"
                                        data-secondary="OPENAI_API_KEY" id="id556"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="APIs (application programming interfaces)"
                                        data-secondary="OpenAI API" data-tertiary="OPENAI_API_KEY environment variable"
                                        id="id557"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="OpenAI" data-secondary="API"
                                        data-tertiary="OPENAI_API_KEY environment variable" id="id558"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="OpenAI Playground"
                                        data-secondary="OpenAI API" data-tertiary="OPENAI_API_KEY environment variable"
                                        id="id559"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="OPENAI_API_KEY environment variable for API key" id="id560"></a>
                                    the code snippet does not explicitly mention the OpenAI API key. This is because the
                                    OpenAI library is designed to automatically look for an environment variable named
                                    <code translate="no">OPENAI_API_KEY</code>. <a contenteditable="false" data-type="indexterm"
                                        data-primary="APIs (application programming interfaces)"
                                        data-secondary="OpenAI API" data-tertiary="key loaded from file"
                                        id="id561"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="OpenAI" data-secondary="API" data-tertiary="key loaded from file"
                                        id="id562"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="OpenAI Playground" data-secondary="OpenAI API"
                                        data-tertiary="key loaded from file" id="id563"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="key for API access"
                                        data-secondary="loaded from file" id="id564"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="openai.api_key_path for API key from file"
                                        id="id565"></a>Alternatively, you can point the <code translate="no">openai</code> module at a
                                    file containing your key with the following code:</p>

                                <pre translate="no" data-type="programlisting"
                                    data-code-language="python"><code translate="no" class="c1"># Load your API key from file</code>
  <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">api_key_path</code> <code translate="no" class="o">=</code> <code translate="no" class="o">&lt;</code><code translate="no" class="n">PATH</code><code translate="no" class="o">&gt;</code><code translate="no" class="p">,</code> </pre>

                                <p>Or you can manually set the API key within your code using the following method:<a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="openai.api_key from environment variable" id="id566"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="environment variable holding API key"
                                        data-secondary="openai.api_key for setting manually" id="id567"></a></p>

                                <pre translate="no" data-type="programlisting"
                                    data-code-language="python"><code translate="no" class="c1"># Load your API key </code>
  <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">api_key</code> <code translate="no" class="o">=</code> <code translate="no" class="n">os</code><code translate="no" class="o">.</code><code translate="no" class="n">getenv</code><code translate="no" class="p">(</code><code translate="no" class="s2">"OPENAI_API_KEY"</code><code translate="no" class="p">)</code></pre>

                                <p>Our recommendation is to follow<a contenteditable="false" data-type="indexterm"
                                        data-primary="APIs (application programming interfaces)"
                                        data-secondary="OpenAI API" data-tertiary="key stored in .env file"
                                        id="id568"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="OpenAI" data-secondary="API"
                                        data-tertiary="key stored in .env file" id="id569"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="OpenAI Playground"
                                        data-secondary="OpenAI API" data-tertiary="key stored in .env file"
                                        id="id570"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="key for API access" data-secondary="stored in .env file"
                                        id="id571"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary=".env file for OpenAI API key" data-primary-sortas="env file"
                                        id="id572"></a> a widespread convention for environment variables: store your
                                    key in a <em>.env</em> file, which is removed from source control in the
                                    <em>.gitignore</em> file. <a contenteditable="false" data-type="indexterm"
                                        data-primary=".env file for OpenAI API key"
                                        data-secondary="load_dotenv Python function" data-primary-sortas="env file"
                                        id="id573"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="Python" data-secondary="load_dotenv function for API key in .env"
                                        id="id574"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="key for API access" data-secondary="stored in .env file"
                                        data-tertiary="load_dotenv Python function" id="id575"></a>In Python, you can
                                    then run the <code translate="no">load_dotenv</code> function to load the environment variables and
                                    import the <em>openai</em> library:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="kn">from</code> <code translate="no" class="nn">dotenv</code> <code translate="no" class="kn">import</code> <code translate="no" class="n">load_dotenv</code>
  <code translate="no" class="n">load_dotenv</code><code translate="no" class="p">()</code>
  <code translate="no" class="kn">import</code> <code translate="no" class="nn">openai</code></pre>

                                <p>It is important to have the <code translate="no">openai</code> import declaration after loading the
                                    <em>.env</em> file; otherwise, the settings for OpenAI will not be applied
                                    correctly.</p>
                                <p>Now that we’ve covered the basic concepts of ChatGPT and GPT-4, we can move on to the
                                    details of their use.<a contenteditable="false" data-type="indexterm"
                                        data-primary="" data-startref="ch02pylib" id="id576"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary=""
                                        data-startref="ch02pylib2" id="id577"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="" data-startref="ch02pylib3"
                                        id="id578"></a><a contenteditable="false" data-type="indexterm" data-primary=""
                                        data-startref="ch02pylib4" id="id579"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="" data-startref="ch02pylib5"
                                        id="id580"></a><a contenteditable="false" data-type="indexterm" data-primary=""
                                        data-startref="ch02pylib6" id="id581"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="" data-startref="ch02pylib7" id="id582"></a>
                                </p>
                            </div>
                        </section>
                    </div>
                </section>
                <section data-type="sect1" data-pdf-bookmark="Using ChatGPT and GPT-4">
                    <div class="sect1" id="using_chatgpt_and_gpt_4">
                        <h1>Using ChatGPT and GPT-4</h1>
                        <p>This section discusses how<a contenteditable="false" data-type="indexterm"
                                data-primary="ChatGPT (OpenAI)" data-secondary="using with OpenAI Python library"
                                data-tertiary="about" id="id583"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="GPT-4 (OpenAI)" data-secondary="using with OpenAI Python library"
                                data-tertiary="about" id="id584"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="GPT-3.5 (OpenAI)" data-secondary="using with OpenAI Python library"
                                data-tertiary="about" id="id585"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="Python" data-secondary="OpenAI Python library"
                                data-tertiary="using ChatGPT and GPT-4" id="ch02-pyuse"></a> to use the model running
                            behind ChatGPT and GPT-4 with the OpenAI Python library.</p>
                        <p>At the time of this writing,<a contenteditable="false" data-type="indexterm"
                                data-primary="ChatGPT (OpenAI)" data-secondary="pricing" id="id586"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="GPT models"
                                data-secondary="pricing" id="id587"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="pricing OpenAI models" data-secondary="least expensive GPT 3.5 Turbo"
                                id="id588"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="GPT-3.5 (OpenAI)" data-secondary="pricing of Turbo" id="id589"></a> GPT
                            3.5 Turbo is the least expensive and most versatile model. Therefore, it is also the best
                            choice for most use cases. Here is an example of its use:<a contenteditable="false"
                                data-type="indexterm" data-primary="openai.ChatCompletion.create()"
                                data-secondary="example code" id="id590"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="ChatCompletion" data-secondary="example code"
                                id="id591"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="ChatGPT (OpenAI)" data-secondary="using with OpenAI Python library"
                                data-tertiary="ChatCompletion example" id="id592"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="GPT-3.5 (OpenAI)"
                                data-secondary="using with OpenAI Python library" data-tertiary="ChatCompletion example"
                                id="id593"></a><a contenteditable="false" data-type="indexterm"
                                data-primary="GPT-4 (OpenAI)" data-secondary="using with OpenAI Python library"
                                data-tertiary="ChatCompletion example" id="id594"></a></p>

                        <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="kn">import</code> <code translate="no" class="nn">openai</code>
  <code translate="no" class="c1"># For GPT 3.5 Turbo, the endpoint is ChatCompletion</code>
  <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">ChatCompletion</code><code translate="no" class="o">.</code><code translate="no" class="n">create</code><code translate="no" class="p">(</code>
      <code translate="no" class="c1"># For GPT 3.5 Turbo, the model is "gpt-3.5-turbo"</code>
      <code translate="no" class="n">model</code><code translate="no" class="o">=</code><code translate="no" class="s2">"gpt-3.5-turbo"</code><code translate="no" class="p">,</code>
      <code translate="no" class="c1"># Conversation as a list of messages.</code>
      <code translate="no" class="n">messages</code><code translate="no" class="o">=</code><code translate="no" class="p">[</code>
          <code translate="no" class="p">{</code><code translate="no" class="s2">"role"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"system"</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"content"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"You are a helpful teacher."</code><code translate="no" class="p">},</code>
          <code translate="no" class="p">{</code>
              <code translate="no" class="s2">"role"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"user"</code><code translate="no" class="p">,</code>
              <code translate="no" class="s2">"content"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"Are there other measures than time complexity for an </code><code translate="no" class="se">\</code>
  <code translate="no" class="s2">            algorithm?"</code><code translate="no" class="p">,</code>
          <code translate="no" class="p">},</code>
          <code translate="no" class="p">{</code>
              <code translate="no" class="s2">"role"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"assistant"</code><code translate="no" class="p">,</code>
              <code translate="no" class="s2">"content"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"Yes, there are other measures besides time complexity </code><code translate="no" class="se">\</code>
  <code translate="no" class="s2">            for an algorithm, such as space complexity."</code><code translate="no" class="p">,</code>
          <code translate="no" class="p">},</code>
          <code translate="no" class="p">{</code><code translate="no" class="s2">"role"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"user"</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"content"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"What is it?"</code><code translate="no" class="p">},</code>
      <code translate="no" class="p">],</code>
  <code translate="no" class="p">)</code></pre>

                        <p>In the preceding example,<a contenteditable="false" data-type="indexterm"
                                data-primary="parameters" data-secondary="ChatCompletion endpoint"
                                data-tertiary="code example" id="id595"></a> we used the minimum number of
                            parameters—that is, the LLM used to do the prediction and the input messages. As you can
                            see, the conversation format in the input messages allows multiple exchanges to be sent to
                            the model. Note that the API does not store previous messages in its context. The question
                            <code translate="no">"</code><code translate="no">What is it?"</code> refers to the previous answer and only makes sense
                            if the model has knowledge of this answer. The entire conversation must be sent each time to
                            simulate a chat session. We will discuss this further in the next section.</p>
                        <p>The GPT 3.5 Turbo and GPT-4 models are optimized<a contenteditable="false"
                                data-type="indexterm" data-primary="GPT-3.5 (OpenAI)"
                                data-secondary="chat sessions and more" id="id596"></a> for chat sessions, but this is
                            not mandatory. Both models can be used for multiturn conversations and single-turn tasks.
                            They also work well for traditional completion tasks if you specify a prompt asking for a
                            completion.</p>
                        <p>Both ChatGPT and GPT-4 use the same endpoint: <code translate="no">openai.ChatCompletion</code>. Changing
                            the model ID allows developers to switch between GPT-3.5 Turbo and GPT-4 without any other
                            code changes.</p>
                        <section data-type="sect2" data-pdf-bookmark="Input Options for the Chat Completion Endpoint">
                            <div class="sect2" id="input_options_for_the_chat_completion_endpoint">
                                <h2>Input Options for the Chat Completion Endpoint</h2>
                                <p>Let’s look in more detail at how to use the <code translate="no">openai.ChatCompletion</code>
                                    endpoint and its <code translate="no">create</code> method.<a contenteditable="false"
                                        data-type="indexterm" data-primary="ChatCompletion"
                                        data-secondary="input options" id="ch02-chcm"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="ChatGPT (OpenAI)"
                                        data-secondary="using with OpenAI Python library"
                                        data-tertiary="ChatCompletion input options" id="ch02-chcm2"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="GPT-4 (OpenAI)"
                                        data-secondary="using with OpenAI Python library"
                                        data-tertiary="ChatCompletion input options" id="ch02-chcm3"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="openai.ChatCompletion.create()"
                                        data-secondary="ChatCompletion input options" id="ch02-chcm4"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="input parameters"
                                        data-secondary="chat completion endpoint" id="ch02-chcm5"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="GPT-3.5 (OpenAI)"
                                        data-secondary="using with OpenAI Python library"
                                        data-tertiary="ChatCompletion input options" id="ch02-chcm6"></a></p>
                                <div data-type="note" epub:type="note">
                                    <h6>Note</h6>
                                    <p>The <code translate="no">create</code> method<a contenteditable="false" data-type="indexterm"
                                            data-primary="openai.ChatCompletion.create()"
                                            data-secondary="create method to call OpenAI models" id="id597"></a><a
                                            contenteditable="false" data-type="indexterm"
                                            data-primary="create method to call OpenAI models" id="id598"></a><a
                                            contenteditable="false" data-type="indexterm" data-primary="GPT models"
                                            data-secondary="create method to call" id="id599"></a> lets users call
                                        OpenAI models. Other methods are available but aren’t helpful for interacting
                                        with the models. You can access the Python library code on OpenAI’s GitHub <a
                                            href="https://oreil.ly/MQ2aQ">Python library repository</a>.</p>
                                </div>
                                <section data-type="sect3" data-pdf-bookmark="Required input parameters">
                                    <div class="sect3" id="required_input_parameters">
                                        <h3>Required input parameters</h3>
                                        <p>The <code translate="no">openai.ChatCompletion</code> endpoint and its <code translate="no">create</code>
                                            method have several input parameters,<a contenteditable="false"
                                                data-type="indexterm" data-primary="parameters"
                                                data-secondary="ChatCompletion endpoint" data-tertiary="required input"
                                                id="id600"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="model input parameter" data-secondary="chat completion"
                                                id="id601"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="messages input parameter for chat completion"
                                                id="id602"></a> but only two are required, as outlined in <a
                                                data-type="xref" href="#table-2-1">Table&nbsp;2-1</a>.</p>
                                        <table class="lines" id="table-2-1">
                                            <caption><span class="label">Table 2-1. </span>Mandatory input parameters
                                            </caption>
                                            <thead>
                                                <tr>
                                                    <th>Field name</th>
                                                    <th>Type</th>
                                                    <th>Description</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr>
                                                    <td>
                                                        <code translate="no">model</code>
                                                    </td>
                                                    <td>String</td>
                                                    <td>The ID of the model to use. Currently, the available models are
                                                        <code translate="no">gpt-4</code>, <code translate="no">gpt-4-0613</code>,
                                                        <code translate="no">gpt-4-32k</code>, <code translate="no">gpt-4-32k-0613</code>,
                                                        <code translate="no">gpt-3.5-turbo</code>, <code translate="no">gpt-3.5-turbo-0613</code>,
                                                        <code translate="no">gpt-3.5-turbo-16k</code>, and
                                                        <code translate="no">gpt-3.5-turbo-16k-0613</code>. It is possible to access
                                                        the list of available models with another endpoint and method
                                                        provided by OpenAI, <code translate="no">openai.Model.list()</code>. Note that
                                                        not all available models are compatible with the
                                                        <code translate="no">openai.ChatCompletion</code> endpoint.</td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                        <span class="keep-together"><code translate="no">messages</code></span>
                                                    </td>
                                                    <td>Array</td>
                                                    <td>An array of <code translate="no">message</code> objects representing a
                                                        conversation. A <code translate="no">message</code> object has two attributes:
                                                        <code translate="no">role</code> (possible values are <code translate="no">system</code>,
                                                        <code translate="no">user</code>, and <code translate="no">assistant</code>) and
                                                        <code translate="no">content</code> (a string with the conversation message).
                                                    </td>
                                                </tr>
                                            </tbody>
                                        </table>
                                        <p>A conversation starts with an optional system message, followed by
                                            alternating user and assistant messages:</p>
                                        <p>The system message helps set the behavior of the assistant. </p>
                                        <p>The user messages are the equivalent of a user typing a question or sentence
                                            in the ChatGPT web interface. They can be generated by the user of the
                                            application or set as an instruction.</p>
                                        <p>The assistant messages have two roles: either they store prior responses to
                                            continue the conversation or they can be set as an instruction to give
                                            examples of desired behavior. Models do not have any memory of past
                                            requests, so storing prior messages is necessary to give context to the
                                            conversation and provide all relevant information. </p>
                                    </div>
                                </section>
                                <section data-type="sect3" data-pdf-bookmark="Length of conversations and tokens ">
                                    <div class="sect3" id="length_of_conversations_and_tokens">
                                        <h3>Length of conversations and tokens </h3>
                                        <p>As seen previously, the total length<a contenteditable="false"
                                                data-type="indexterm" data-primary="tokenization in GPT models"
                                                data-secondary="tokens" data-tertiary="total length of conversation"
                                                id="id603"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="ChatGPT (OpenAI)"
                                                data-secondary="using with OpenAI Python library"
                                                data-tertiary="length of conversation and tokens" id="id604"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="GPT-4 (OpenAI)"
                                                data-secondary="using with OpenAI Python library"
                                                data-tertiary="length of conversation and tokens" id="id605"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="GPT-3.5 (OpenAI)"
                                                data-secondary="using with OpenAI Python library"
                                                data-tertiary="length of conversation and tokens" id="id606"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="pricing OpenAI models" data-secondary="tokens used"
                                                data-tertiary="length of conversation and tokens" id="id607"></a><a
                                                contenteditable="false" data-type="indexterm" data-primary="cost"
                                                data-see="pricing OpenAI models" id="id608"></a> of the conversation
                                            will be correlated to the total number of tokens. This will have an impact
                                            on the following:</p>
                                        <dl>
                                            <dt>Cost</dt>
                                            <dd>
                                                <p>The pricing is by token.</p>
                                            </dd>
                                            <dt>Timing</dt>
                                            <dd>
                                                <p>The more tokens there are, the more time the response will take—up to
                                                    a couple of minutes. </p>
                                            </dd>
                                            <dt>The model working or not </dt>
                                            <dd>
                                                <p>The total number of tokens must be less than the model’s maximum
                                                    limit. You can find examples of token limits in <a data-type="xref"
                                                        href="#considerations">“Considerations”</a>.</p>
                                            </dd>
                                        </dl>
                                        <p>As you can see, it is necessary<a contenteditable="false"
                                                data-type="indexterm" data-primary="tokenization in GPT models"
                                                data-secondary="tokens" data-tertiary="management of" id="id609"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="pricing OpenAI models" data-secondary="tokens used"
                                                data-tertiary="management of" id="id610"></a><a contenteditable="false"
                                                data-type="indexterm"
                                                data-primary="max_tokens input parameter for chat completion"
                                                data-secondary="managing for cost control" id="id611"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="pricing OpenAI models" data-secondary="tokens used"
                                                data-tertiary="max_tokens input parameter" id="id612"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="tokenization in GPT models" data-secondary="tokens"
                                                data-tertiary="max_tokens input parameter" id="id613"></a> to carefully
                                            manage the length of the conversation. You can control the number of input
                                            tokens by managing the length of your messages and control the number of
                                            output tokens via the <code translate="no">max_tokens</code> parameter, as detailed in the
                                            next subsection.</p>
                                        <div data-type="tip">
                                            <h6>Tip</h6>
                                            <p>OpenAI provides a library<a contenteditable="false" data-type="indexterm"
                                                    data-primary="tokenization in GPT models" data-secondary="tokens"
                                                    data-tertiary="tiktoken package to count tokens" id="id614"></a><a
                                                    contenteditable="false" data-type="indexterm"
                                                    data-primary="tiktoken package" data-secondary="counting tokens"
                                                    id="id615"></a><a contenteditable="false" data-type="indexterm"
                                                    data-primary="resources online"
                                                    data-secondary="tiktoken package to count tokens" id="id616"></a>
                                                named <a href="https://oreil.ly/zxRIi"><em>tiktoken</em></a> that allows
                                                developers to count how many tokens are in a text string. We highly
                                                recommend using this library to estimate costs before making the call to
                                                the endpoint. </p>
                                        </div>
                                    </div>
                                </section>
                                <section data-type="sect3" data-pdf-bookmark="Additional optional parameters">
                                    <div class="sect3" id="additional_optional_parameters">
                                        <h3>Additional optional parameters</h3>
                                        <p>OpenAI provides several other options<a contenteditable="false"
                                                data-type="indexterm" data-primary="parameters"
                                                data-secondary="ChatCompletion endpoint" data-tertiary="optional input"
                                                id="id617"></a> to fine-tune how you interact with the library. We will
                                            not detail all the parameters here, but we recommend having a look at <a
                                                data-type="xref" href="#table-2-2">Table&nbsp;2-2</a>.<a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="functions input parameter for chat completion"
                                                id="id618"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="function_call input parameter for chat completion"
                                                id="id619"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="temperature input parameter for chat completion"
                                                id="id620"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="n parameter for multiple chat completions"
                                                data-secondary="temperature and" id="id621"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="n parameter for multiple chat completions"
                                                id="id622"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="temperature input parameter for chat completion"
                                                data-secondary="n parameter and" id="id623"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="stream Boolean input parameter for chat completion"
                                                id="id624"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="max_tokens input parameter for chat completion"
                                                id="id625"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="parameters" data-secondary="max_tokens input parameter"
                                                id="id626"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="parameters" data-secondary="max_tokens input parameter"
                                                data-tertiary="managing for cost control" id="id627"></a></p>
                                        <table class="lines" id="table-2-2">
                                            <caption><span class="label">Table 2-2. </span>A selection of additional
                                                optional parameters</caption>
                                            <thead>
                                                <tr>
                                                    <th>Field name</th>
                                                    <th>Type</th>
                                                    <th>Description</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr>
                                                    <td>
                                                        <code translate="no">functions</code>
                                                    </td>
                                                    <td>Array</td>
                                                    <td>An array of available functions. See <a data-type="xref"
                                                            href="#from_text_completions_to_functions">“From Text
                                                            Completions to Functions”</a> for more details on how to use
                                                        <code translate="no">functions</code>.</td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                        <span class="keep-together"><code translate="no">function_call</code></span>
                                                    </td>
                                                    <td>String or object</td>
                                                    <td>Controls how the model responds:
                                                        <ul>
                                                            <li><code translate="no">none</code> means the model must respond to the
                                                                user in a standard way.</li>
                                                            <li> <code translate="no">{"name":"my_function"}</code> means the model
                                                                must give an answer that uses the specified function.
                                                            </li>
                                                            <li><code translate="no">auto</code> means the model can choose between a
                                                                standard response to the user or a function defined in
                                                                the <code translate="no">functions</code> array. </li>
                                                        </ul>
                                                    </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                        <span class="keep-together"><code translate="no">temperature</code></span>
                                                    </td>
                                                    <td>Number (default: 1; accepted values: between 0 and 2)</td>
                                                    <td>A temperature of <code translate="no">0</code> means the call to the model will
                                                        likely return the same completion for a given input. Even though
                                                        the responses will be highly consistent, OpenAI does not
                                                        guarantee a deterministic output. The higher the value is, the
                                                        more random the completion will be. LLMs generate answers by
                                                        predicting a series of tokens one at a time. Based on the input
                                                        context, they assign probabilities to each potential token. When
                                                        the temperature parameter is set to <code translate="no">0</code>, the LLM will
                                                        always choose the token with the highest probability. A higher
                                                        temperature allows for more varied and creative outputs. </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                        <code translate="no">n</code>
                                                    </td>
                                                    <td>Integer (default: 1)</td>
                                                    <td>With this parameter, it is possible to generate multiple chat
                                                        completions for a given input message. However, with a
                                                        temperature of <code translate="no">0</code> as the input parameter, you will
                                                        get multiple responses, but they will all be identical or very
                                                        similar.</td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                        <code translate="no">stream</code>
                                                    </td>
                                                    <td>Boolean (default: false)</td>
                                                    <td>As its name suggests, this parameter will allow the answer to be
                                                        in a stream format. This means partial messages will be sent
                                                        gradually, like in the ChatGPT interface. This can make for a
                                                        better user experience when the completions are long.</td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                        <code translate="no">max_tokens</code>
                                                    </td>
                                                    <td>Integer</td>
                                                    <td>This parameter signifies the maximum number of tokens to
                                                        generate in the chat completion. This parameter is optional, but
                                                        we highly recommend setting it as a good practice to keep your
                                                        costs under control. Note that this parameter may be ignored or
                                                        not respected if it is too high: the total length of the input
                                                        and generated tokens is capped by the model’s token limitations.
                                                    </td>
                                                </tr>
                                            </tbody>
                                        </table>
                                        <p>You can find more details and<a contenteditable="false" data-type="indexterm"
                                                data-primary="parameters" data-secondary="documentation link"
                                                id="id628"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="resources online" data-secondary="OpenAI"
                                                data-tertiary="chat completion parameters documentation" id="id629"></a>
                                            other parameters on the <a
                                                href="https://platform.openai.com/docs/api-reference/chat">official
                                                documentation page</a>.<a contenteditable="false" data-type="indexterm"
                                                data-primary="" data-startref="ch02-chcm" id="id630"></a><a
                                                contenteditable="false" data-type="indexterm" data-primary=""
                                                data-startref="ch02-chcm2" id="id631"></a><a contenteditable="false"
                                                data-type="indexterm" data-primary="" data-startref="ch02-chcm3"
                                                id="id632"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="" data-startref="ch02-chcm4" id="id633"></a><a
                                                contenteditable="false" data-type="indexterm" data-primary=""
                                                data-startref="ch02-chcm5" id="id634"></a><a contenteditable="false"
                                                data-type="indexterm" data-primary="" data-startref="ch02-chcm6"
                                                id="id635"></a></p>
                                    </div>
                                </section>
                            </div>
                        </section>
                        <section data-type="sect2"
                            data-pdf-bookmark="Output Result Format for the Chat Completion Endpoint">
                            <div class="sect2" id="output_result_format_for_the_chat_completion_endpo">
                                <h2>Output Result Format for the Chat Completion Endpoint</h2>
                                <p>Now that you have the information you need to query chat-based models, let’s see how
                                    to use the results.<a contenteditable="false" data-type="indexterm"
                                        data-primary="ChatGPT (OpenAI)"
                                        data-secondary="using with OpenAI Python library"
                                        data-tertiary="ChatCompletion output result format" id="id636"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="ChatCompletion"
                                        data-secondary="output result format" id="id637"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="GPT-4 (OpenAI)"
                                        data-secondary="using with OpenAI Python library"
                                        data-tertiary="ChatCompletion output result format" id="id638"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="GPT-3.5 (OpenAI)"
                                        data-secondary="using with OpenAI Python library"
                                        data-tertiary="ChatCompletion output result format" id="id639"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="Hello world example Python code"
                                        data-secondary="output result format" id="id640"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="APIs (application programming interfaces)"
                                        data-secondary="OpenAI API" data-tertiary="Hello world example"
                                        id="id641"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="OpenAI" data-secondary="API" data-tertiary="Hello world example"
                                        id="id642"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="output result format" data-secondary="chat completion endpoint"
                                        id="id643"></a></p>
                                <p>Following is the complete response for the “Hello World” example:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="p">{</code>
      <code translate="no" class="s2">"choices"</code><code translate="no" class="p">:</code> <code translate="no" class="p">[</code>
          <code translate="no" class="p">{</code>
              <code translate="no" class="s2">"finish_reason"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"stop"</code><code translate="no" class="p">,</code>
              <code translate="no" class="s2">"index"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">0</code><code translate="no" class="p">,</code>
              <code translate="no" class="s2">"message"</code><code translate="no" class="p">:</code> <code translate="no" class="p">{</code>
                  <code translate="no" class="s2">"content"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"Hello there! How may I assist you today?"</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"role"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"assistant"</code><code translate="no" class="p">,</code>
              <code translate="no" class="p">},</code>
          <code translate="no" class="p">}</code>
      <code translate="no" class="p">],</code>
      <code translate="no" class="s2">"created"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">1681134595</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"id"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"chatcmpl-73mC3tbOlMNHGci3gyy9nAxIP2vsU"</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"model"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"gpt-3.5-turbo"</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"object"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"chat.completion"</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"usage"</code><code translate="no" class="p">:</code> <code translate="no" class="p">{</code><code translate="no" class="s2">"completion_tokens"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">10</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"prompt_tokens"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">11</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"total_tokens"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">21</code><code translate="no" class="p">},</code>
  <code translate="no" class="p">}</code></pre>

                                <p>The generated output is detailed in <a data-type="xref"
                                        href="#table-2-3">Table&nbsp;2-3</a>.<a contenteditable="false"
                                        data-type="indexterm" data-primary="parameters"
                                        data-secondary="ChatCompletion endpoint" data-tertiary="output"
                                        id="id644"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="choices output parameter" data-secondary="chat completion"
                                        id="id645"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="created output parameter" data-secondary="chat completion"
                                        id="id646"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="id output parameter" data-secondary="chat completion"
                                        id="id647"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="model output parameter" data-secondary="chat completion"
                                        id="id648"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="object output parameter" data-secondary="chat completion"
                                        id="id649"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="usage output parameter" data-secondary="chat completion"
                                        id="id650"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="pricing OpenAI models" data-secondary="tokens used"
                                        data-tertiary="usage output parameter" id="id651"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="tokenization in GPT models"
                                        data-secondary="tokens" data-tertiary="usage output parameter" id="id652"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="prompt_tokens for input tokens" id="id653"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="completion_tokens for output tokens" id="id654"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="total_tokens value"
                                        id="id655"></a></p>
                                <table class="lines" id="table-2-3">
                                    <caption><span class="label">Table 2-3. </span>Description of the output from the
                                        chat completion base models</caption>
                                    <thead>
                                        <tr>
                                            <th>Field name</th>
                                            <th>Type</th>
                                            <th>Description</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>
                                                <code translate="no">choices</code>
                                            </td>
                                            <td>Array of “choice” object</td>
                                            <td>An array that contains the actual response of the model. By default,
                                                this array will only have one element, which can be changed with the
                                                parameter <code translate="no">n</code> (see <a data-type="xref"
                                                    href="#additional_optional_parameters">“Additional optional
                                                    parameters”</a>). This element contains the following:
                                                <ul>
                                                    <li><code translate="no">finish_reason</code><code translate="no"> - </code><code translate="no">string</code>:
                                                        The reason the answer from the model is finished. In our “Hello
                                                        World” example, we can see the <code translate="no">finish_reason</code> is
                                                        <code translate="no">stop</code>, which means we received the complete response
                                                        from the model. If there is an error during the output
                                                        generation, it will appear in this field.</li>
                                                    <li><code translate="no">index</code><code translate="no"> - </code><code translate="no">integer</code>: The
                                                        index of the <code translate="no">choice</code> object from the
                                                        <code translate="no">choices</code> array. </li>
                                                    <li><code translate="no">message</code><code translate="no"> - </code><code translate="no">object</code>:
                                                        Contains a <code translate="no">role</code> and either a <code translate="no">content</code>
                                                        or a <code translate="no">function_call</code>. The <code translate="no">role</code> will
                                                        always be <code translate="no">assistant</code>, and the <code translate="no">content</code>
                                                        will include the text generated by the model. Usually we want to
                                                        get this string:
                                                        <code translate="no">response['choices'][0]​['mes⁠sage']['content']</code>. For
                                                        details on how to use <code translate="no">function_call</code>, see <a
                                                            data-type="xref"
                                                            href="#from_text_completions_to_functions">“From Text
                                                            Completions to Functions”</a>.</li>
                                                </ul>
                                            </td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <code translate="no">created </code>
                                            </td>
                                            <td>Timestamp</td>
                                            <td>The date in a timestamp format at the time of the generation. In our
                                                “Hello World” example, this timestamp translates to Monday, April 10,
                                                2023 1:49:55 p.m.</td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <code translate="no">id</code>
                                            </td>
                                            <td>String</td>
                                            <td>A technical identifier used internally by OpenAI.</td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <code translate="no">model</code>
                                            </td>
                                            <td>String</td>
                                            <td>The model used. This is the same as the model set as input.</td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <code translate="no">object</code>
                                            </td>
                                            <td>String</td>
                                            <td>Should always be <code translate="no">chat.completion</code> for GPT-4 and GPT-3.5
                                                models, as we are using the chat completion endpoint.</td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <code translate="no">usage</code>
                                            </td>
                                            <td>String</td>
                                            <td>Gives information on the number of tokens used in this query and
                                                therefore gives you pricing information. The <code translate="no">prompt_tokens</code>
                                                represents the number of tokens used in the input, the
                                                <code translate="no">completion_tokens</code> is the number of tokens in the output,
                                                and as you might have guessed, <code translate="no">total_tokens</code> =
                                                <code translate="no">prompt_tokens</code> + <code translate="no">completion_tokens</code>. </td>
                                        </tr>
                                    </tbody>
                                </table>
                                <div data-type="tip">
                                    <h6>Tip</h6>
                                    <p>If you want to have multiple choices<a contenteditable="false"
                                            data-type="indexterm"
                                            data-primary="n parameter for multiple chat completions"
                                            data-secondary="prompt_tokens and completion_tokens values" id="id656"></a>
                                        and use an <code translate="no">n</code> parameter higher than 1, you will see that the
                                        <code translate="no">prompt_tokens</code> value will not change, but the
                                        <code translate="no">completion_tokens</code> value will be roughly multiplied by
                                        <code translate="no">n</code>.</p>
                                </div>
                            </div>
                        </section>
                        <section data-type="sect2" data-pdf-bookmark="From Text Completions to Functions">
                            <div class="sect2" id="from_text_completions_to_functions">
                                <h2>From Text Completions to Functions</h2>
                                <p>OpenAI introduced the possibility<a contenteditable="false" data-type="indexterm"
                                        data-primary="ChatGPT (OpenAI)"
                                        data-secondary="using with OpenAI Python library"
                                        data-tertiary="JSON object function call output" id="ch02-jsno"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="GPT-4 (OpenAI)"
                                        data-secondary="using with OpenAI Python library"
                                        data-tertiary="JSON object function call output" id="ch02-jsno2"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="JSON object function call output" id="ch02-jsno3"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="function calls via JSON object output" id="ch02-jsno4"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="GPT-3.5 (OpenAI)"
                                        data-secondary="using with OpenAI Python library"
                                        data-tertiary="JSON object function call output" id="ch02-jsno5"></a> for its
                                    models to output a JSON object containing arguments to call functions. The model
                                    will not be able to call the function itself, but rather will convert a text input
                                    into an output format that can be executed programmatically by the caller.</p>
                                <p>This is particularly useful when the result of the call to the OpenAI API needs to be
                                    processed by the rest of your code: instead of creating a complicated prompt to
                                    ensure that the model answers in a specific format that can be parsed by your code,
                                    you can use a function definition to convert natural language into API calls or
                                    database queries, extract structured data from text, and create chatbots that answer
                                    questions by calling external tools.</p>
                                <p>As you saw in <a data-type="xref" href="#table-2-2">Table&nbsp;2-2</a>, which details
                                    the input options for the chat completion endpoint, <a contenteditable="false"
                                        data-type="indexterm" data-primary="function calls via JSON object output"
                                        data-secondary="function object details" id="id657"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="JSON object function call output"
                                        data-secondary="function object details" id="id658"></a>function definitions
                                    need to be passed as an array of function objects. The function object is detailed
                                    in <a data-type="xref" href="#table-2-4">Table&nbsp;2-4</a>.</p>
                                <table class="lines" id="table-2-4">
                                    <caption><span class="label">Table 2-4. </span>Details of the function object
                                    </caption>
                                    <thead>
                                        <tr>
                                            <th>Field name</th>
                                            <th>Type</th>
                                            <th>Description</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>
                                                <code translate="no">name</code>
                                            </td>
                                            <td>String (required)</td>
                                            <td>The name of the function. </td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <code translate="no">description</code>
                                            </td>
                                            <td>String</td>
                                            <td>The description of the function.</td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <code translate="no">parameters</code>
                                            </td>
                                            <td>Object</td>
                                            <td>The parameters expected by the function. These parameters are expected
                                                to be described in a <a href="http://json-schema.org">JSON Schema</a>
                                                format.</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <p>As an example, imagine that we have a database that contains information relative to
                                    company products. We can define a function that executes a search against this
                                    database:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="c1"># Example function</code>
  <code translate="no" class="k">def</code> <code translate="no" class="nf">find_product</code><code translate="no" class="p">(</code><code translate="no" class="n">sql_query</code><code translate="no" class="p">):</code>
      <code translate="no" class="c1"># Execute query here</code>
      <code translate="no" class="n">results</code> <code translate="no" class="o">=</code> <code translate="no" class="p">[</code>
          <code translate="no" class="p">{</code><code translate="no" class="s2">"name"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"pen"</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"color"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"blue"</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"price"</code><code translate="no" class="p">:</code> <code translate="no" class="mf">1.99</code><code translate="no" class="p">},</code>
          <code translate="no" class="p">{</code><code translate="no" class="s2">"name"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"pen"</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"color"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"red"</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"price"</code><code translate="no" class="p">:</code> <code translate="no" class="mf">1.78</code><code translate="no" class="p">},</code>
      <code translate="no" class="p">]</code>
      <code translate="no" class="k">return</code> <code translate="no" class="n">results</code></pre>

                                <p>Next, we define the specifications of the functions:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="c1"># Function definition</code>
  <code translate="no" class="n">functions</code> <code translate="no" class="o">=</code> <code translate="no" class="p">[</code>
      <code translate="no" class="p">{</code>
          <code translate="no" class="s2">"name"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"find_product"</code><code translate="no" class="p">,</code>
          <code translate="no" class="s2">"description"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"Get a list of products from a sql query"</code><code translate="no" class="p">,</code>
          <code translate="no" class="s2">"parameters"</code><code translate="no" class="p">:</code> <code translate="no" class="p">{</code>
              <code translate="no" class="s2">"type"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"object"</code><code translate="no" class="p">,</code>
              <code translate="no" class="s2">"properties"</code><code translate="no" class="p">:</code> <code translate="no" class="p">{</code>
                  <code translate="no" class="s2">"sql_query"</code><code translate="no" class="p">:</code> <code translate="no" class="p">{</code>
                      <code translate="no" class="s2">"type"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"string"</code><code translate="no" class="p">,</code>
                      <code translate="no" class="s2">"description"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"A SQL query"</code><code translate="no" class="p">,</code>
                  <code translate="no" class="p">}</code>
              <code translate="no" class="p">},</code>
              <code translate="no" class="s2">"required"</code><code translate="no" class="p">:</code> <code translate="no" class="p">[</code><code translate="no" class="s2">"sql_query"</code><code translate="no" class="p">],</code>
          <code translate="no" class="p">},</code>
      <code translate="no" class="p">}</code>
  <code translate="no" class="p">]</code></pre>

                                <p>We can then create a conversation and call the <code translate="no">openai.ChatCompletion</code>
                                    endpoint:</p>

                                <pre translate="no" data-type="programlisting"
                                    data-code-language="python"><code translate="no" class="c1"># Example question</code>
  <code translate="no" class="n">user_question</code> <code translate="no" class="o">=</code> <code translate="no" class="s2">"I need the top 2 products where the price is less than 2.00"</code>
  <code translate="no" class="n">messages</code> <code translate="no" class="o">=</code> <code translate="no" class="p">[{</code><code translate="no" class="s2">"role"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"user"</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"content"</code><code translate="no" class="p">:</code> <code translate="no" class="n">user_question</code><code translate="no" class="p">}]</code>
  <code translate="no" class="c1"># Call the openai.ChatCompletion endpoint with the function definition</code>
  <code translate="no" class="n">response</code> <code translate="no" class="o">=</code> <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">ChatCompletion</code><code translate="no" class="o">.</code><code translate="no" class="n">create</code><code translate="no" class="p">(</code>
          <code translate="no" class="n">model</code><code translate="no" class="o">=</code><code translate="no" class="s2">"gpt-3.5-turbo-0613"</code><code translate="no" class="p">,</code> <code translate="no" class="n">messages</code><code translate="no" class="o">=</code><code translate="no" class="n">messages</code><code translate="no" class="p">,</code> <code translate="no" class="n">functions</code><code translate="no" class="o">=</code><code translate="no" class="n">functions</code>
  <code translate="no" class="p">)</code>
  <code translate="no" class="n">response_message</code> <code translate="no" class="o">=</code> <code translate="no" class="n">response</code><code translate="no" class="p">[</code><code translate="no" class="s2">"choices"</code><code translate="no" class="p">][</code><code translate="no" class="mi">0</code><code translate="no" class="p">][</code><code translate="no" class="s2">"message"</code><code translate="no" class="p">]</code>
  <code translate="no" class="n">messages</code><code translate="no" class="o">.</code><code translate="no" class="n">append</code><code translate="no" class="p">(</code><code translate="no" class="n">response_message</code><code translate="no" class="p">)</code></pre>

                                <p>The model has created a query that we can use. If we print the
                                    <code translate="no">function_call</code> object from the response, we get:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="s2">"function_call"</code><code translate="no" class="p">:</code> <code translate="no" class="p">{</code>
          <code translate="no" class="s2">"name"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"find_product"</code><code translate="no" class="p">,</code>
          <code translate="no" class="s2">"arguments"</code><code translate="no" class="p">:</code> <code translate="no" class="s1">'{</code><code translate="no" class="se">\n</code><code translate="no" class="s1">  "sql_query": "SELECT * FROM products </code><code translate="no" class="se">\</code>
  <code translate="no" class="s1">    WHERE price &lt; 2.00 ORDER BY price ASC LIMIT 2"</code><code translate="no" class="se">\n</code><code translate="no" class="s1">}'</code><code translate="no" class="p">,</code>
      <code translate="no" class="p">}</code></pre>

                                <p>Next, we execute the function and continue the conversation with the result:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="c1"># Call the function</code>
  <code translate="no" class="n">function_args</code> <code translate="no" class="o">=</code> <code translate="no" class="n">json</code><code translate="no" class="o">.</code><code translate="no" class="n">loads</code><code translate="no" class="p">(</code>
      <code translate="no" class="n">response_message</code><code translate="no" class="p">[</code><code translate="no" class="s2">"function_call"</code><code translate="no" class="p">][</code><code translate="no" class="s2">"arguments"</code><code translate="no" class="p">]</code>
  <code translate="no" class="p">)</code>
  <code translate="no" class="n">products</code> <code translate="no" class="o">=</code> <code translate="no" class="n">find_product</code><code translate="no" class="p">(</code><code translate="no" class="n">function_args</code><code translate="no" class="o">.</code><code translate="no" class="n">get</code><code translate="no" class="p">(</code><code translate="no" class="s2">"sql_query"</code><code translate="no" class="p">))</code>
  <code translate="no" class="c1"># Append the function's response to the messages</code>
  <code translate="no" class="n">messages</code><code translate="no" class="o">.</code><code translate="no" class="n">append</code><code translate="no" class="p">(</code>
      <code translate="no" class="p">{</code>
          <code translate="no" class="s2">"role"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"function"</code><code translate="no" class="p">,</code>
          <code translate="no" class="s2">"name"</code><code translate="no" class="p">:</code> <code translate="no" class="n">function_name</code><code translate="no" class="p">,</code>
          <code translate="no" class="s2">"content"</code><code translate="no" class="p">:</code> <code translate="no" class="n">json</code><code translate="no" class="o">.</code><code translate="no" class="n">dumps</code><code translate="no" class="p">(</code><code translate="no" class="n">products</code><code translate="no" class="p">),</code>
      <code translate="no" class="p">}</code>
  <code translate="no" class="p">)</code>
  <code translate="no" class="c1"># Format the function's response into natural language</code>
  <code translate="no" class="n">response</code> <code translate="no" class="o">=</code> <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">ChatCompletion</code><code translate="no" class="o">.</code><code translate="no" class="n">create</code><code translate="no" class="p">(</code>
      <code translate="no" class="n">model</code><code translate="no" class="o">=</code><code translate="no" class="s2">"gpt-3.5-turbo-0613"</code><code translate="no" class="p">,</code>
      <code translate="no" class="n">messages</code><code translate="no" class="o">=</code><code translate="no" class="n">messages</code><code translate="no" class="p">,</code>
  <code translate="no" class="p">)</code></pre>

                                <p>And finally, we extract the final response and obtain the following:</p>

                                <pre translate="no" data-type="programlisting">The top 2 products where the price is less than $2.00 are:
  1. Pen (Blue) - Price: $1.99
  2. Pen (Red) - Price: $1.78</pre>

                                <p>This simple example demonstrates how functions can be useful to build a solution that
                                    allows end users to interact in natural language with a database. The function
                                    definitions allow you to constrain the model to answer exactly as you want it to,
                                    and integrate its response into an application.<a contenteditable="false"
                                        data-type="indexterm" data-primary="" data-startref="ch02-pyuse"
                                        id="id659"></a><a contenteditable="false" data-type="indexterm" data-primary=""
                                        data-startref="ch02-jsno" id="id660"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="" data-startref="ch02-jsno2"
                                        id="id661"></a><a contenteditable="false" data-type="indexterm" data-primary=""
                                        data-startref="ch02-jsno3" id="id662"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="" data-startref="ch02-jsno4"
                                        id="id663"></a><a contenteditable="false" data-type="indexterm" data-primary=""
                                        data-startref="ch02-jsno5" id="id664"></a></p>
                            </div>
                        </section>
                    </div>
                </section>
                <section data-type="sect1" data-pdf-bookmark="Using Other Text Completion Models">
                    <div class="sect1" id="using_other_text_completion_models">
                        <h1>Using Other Text Completion Models</h1>
                        <p>As mentioned, OpenAI provides several<a contenteditable="false" data-type="indexterm"
                                data-primary="GPT models" data-secondary="text completion models" id="ch02-txcmp"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="text completion"
                                data-secondary="other text completion models" id="ch02-txcmp2"></a> additional models
                            besides the GPT-3 and GPT-3.5 series. These models use a different endpoint than the ChatGPT
                            and GPT-4 models. Even though the GPT 3.5 Turbo model is usually the best choice in terms of
                            both price and performance, it is helpful to know how to use the completion models,
                            particularly for use cases such as fine-tuning, in which the GPT-3 completion models are the
                            only choice. </p>
                        <div data-type="note" epub:type="note">
                            <h6>Note</h6>
                            <p>OpenAI has released a deprecation plan<a contenteditable="false" data-type="indexterm"
                                    data-primary="text completion" data-secondary="endpoint deprecation" id="id665"></a>
                                for the text completion endpoint. We introduce this endpoint here only because
                                completion base models are the only ones that can be fine-tuned. OpenAI will provide a
                                solution for fine-tuning chat-based models by January 2024. As it is not available yet,
                                we do not have the necessary information to describe it here.</p>
                        </div>
                        <p>There is an important difference<a contenteditable="false" data-type="indexterm"
                                data-primary="ChatCompletion" data-secondary="text completion versus" id="id666"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="text completion"
                                data-secondary="chat completion versus" id="id667"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="openai.ChatCompletion.create()"
                                data-secondary="chat completion versus text completion" id="id668"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="openai.Completion.create()"
                                data-secondary="text completion versus chat completion" id="id669"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="prompts"
                                data-secondary="chat completion versus text completion" id="id670"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="prompt engineering"
                                data-secondary="chat completion versus text completion" id="id671"></a> between text
                            completion and chat completion: as you might guess, both generate text, but chat completion
                            is optimized for conversations. As you can see in the following code snippet, the main
                            difference with the <code translate="no">openai.ChatCompletion</code> endpoint is the prompt format.
                            Chat-based models must be in conversation format; for completion, it is a single prompt:</p>

                        <pre translate="no" data-type="programlisting"
                            data-code-language="python"><code translate="no" class="kn">import</code> <code translate="no" class="nn">openai</code>
  <code translate="no" class="c1"># Call the openai Completion endpoint</code>
  <code translate="no" class="n">response</code> <code translate="no" class="o">=</code> <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">Completion</code><code translate="no" class="o">.</code><code translate="no" class="n">create</code><code translate="no" class="p">(</code>
      <code translate="no" class="n">model</code><code translate="no" class="o">=</code><code translate="no" class="s2">"text-davinci-003"</code><code translate="no" class="p">,</code> <code translate="no" class="n">prompt</code><code translate="no" class="o">=</code><code translate="no" class="s2">"Hello World!"</code>
  <code translate="no" class="p">)</code>
  <code translate="no" class="c1"># Extract the response</code>
  <code translate="no" class="nb">print</code><code translate="no" class="p">(</code><code translate="no" class="n">response</code><code translate="no" class="p">[</code><code translate="no" class="s2">"choices"</code><code translate="no" class="p">][</code><code translate="no" class="mi">0</code><code translate="no" class="p">][</code><code translate="no" class="s2">"text"</code><code translate="no" class="p">])</code></pre>

                        <p>The preceding code snippet will output a completion similar to the following:</p>

                        <pre translate="no" data-type="programlisting">"\n\nIt's a pleasure to meet you. I'm new to the world"</pre>


                        <p>The next section goes through the details of the text completion endpoint’s input options.<a
                                contenteditable="false" data-type="indexterm" data-primary="" data-startref="ch02-txcmp"
                                id="id672"></a><a contenteditable="false" data-type="indexterm" data-primary=""
                                data-startref="ch02-txcmp2" id="id673"></a></p>
                        <section data-type="sect2" data-pdf-bookmark="Input Options for the Text Completion Endpoint">
                            <div class="sect2" id="input_options_for_the_text_completion_endpoint">
                                <h2>Input Options for the Text Completion Endpoint</h2>
                                <p>The set of input options for<a contenteditable="false" data-type="indexterm"
                                        data-primary="input parameters" data-secondary="text completion endpoint"
                                        id="id674"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="text completion" data-secondary="input options" id="id675"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="openai.Completion.create()" data-secondary="input parameters"
                                        id="id676"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="parameters" data-secondary="text completion input parameters"
                                        id="id677"></a> <code translate="no">openai.Completion.create</code> is very similar to what we
                                    saw previously with the chat endpoint. In this section, we will discuss the main
                                    input parameters and consider the impact of the length of the prompt.</p>
                                <section data-type="sect3" data-pdf-bookmark="Main input parameters">
                                    <div class="sect3" id="main_input_parameters">
                                        <h3>Main input parameters</h3>
                                        <p>The required input parameters and a selection of optional parameters that we
                                            feel are most useful are described in <a data-type="xref"
                                                href="#table-2-5">Table&nbsp;2-5</a>.<a contenteditable="false"
                                                data-type="indexterm" data-primary="model input parameter"
                                                data-secondary="text completion" id="id678"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="prompt input parameter for text completion"
                                                id="id679"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="max_tokens input parameter for text completion"
                                                id="id680"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="suffix input parameter for text completion"
                                                id="id681"></a></p>
                                        <table class="pagebreak-before less_space lines" id="table-2-5">
                                            <caption><span class="label">Table 2-5. </span>Required parameters and
                                                optional parameters for the text completion endpoint</caption>
                                            <thead>
                                                <tr>
                                                    <th>Field name</th>
                                                    <th>Type</th>
                                                    <th>Description</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr>
                                                    <td>
                                                        <code translate="no">model</code>
                                                    </td>
                                                    <td>String (required)</td>
                                                    <td>ID of the model to use (the same as with
                                                        <code translate="no">openai.ChatCompletion</code>). This is the only required
                                                        option.</td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                        <code translate="no">prompt</code>
                                                    </td>
                                                    <td>String or array (default: <code translate="no">&lt;|endoftext|&gt;</code>)</td>
                                                    <td>The prompt to generate completions for. This is the main
                                                        difference from the <code translate="no">openai.ChatCompletion</code> endpoint.
                                                        The <code translate="no">openai.Completion.create</code> endpoint should be
                                                        encoded as a string, array of strings, array of tokens, or array
                                                        of token arrays. If no prompt is provided to the model, it will
                                                        generate text as if from the beginning of a new document.</td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                        <code translate="no">max_tokens</code>
                                                    </td>
                                                    <td>Integer</td>
                                                    <td>The maximum number of tokens to generate in the chat completion.
                                                        The default value of this parameter is <code translate="no">16</code>, which
                                                        may be too low for some use cases and should be adjusted
                                                        according to your needs. </td>
                                                </tr>
                                                <tr>
                                                    <td>
                                                        <code translate="no">suffix</code>
                                                    </td>
                                                    <td>String (default: null)</td>
                                                    <td>The text that comes after the completion. This parameter allows
                                                        adding a suffix text. It also allows making insertions.</td>
                                                </tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </section>
                                <section data-type="sect3" data-pdf-bookmark="Length of prompts and tokens">
                                    <div class="sect3" id="length_of_prompts_and_tokens">
                                        <h3>Length of prompts and tokens</h3>
                                        <p>Just as with the chat models,<a contenteditable="false" data-type="indexterm"
                                                data-primary="pricing OpenAI models" data-secondary="text completion"
                                                id="id682"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="text completion" data-secondary="pricing"
                                                id="id683"></a><a contenteditable="false" data-type="indexterm"
                                                data-primary="max_tokens input parameter for text completion"
                                                data-secondary="managing for cost control" id="id684"></a><a
                                                contenteditable="false" data-type="indexterm" data-primary="parameters"
                                                data-secondary="max_tokens input parameter"
                                                data-tertiary="managing for cost control" id="id685"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="pricing OpenAI models" data-secondary="tokens used"
                                                data-tertiary="max_tokens input parameter" id="id686"></a> pricing will
                                            depend on the input you send and the output you receive. For the input
                                            message, you must carefully manage the length of the prompt parameter, as
                                            well as the suffix if one is used. For the output you receive, use
                                            <code translate="no">max_tokens</code><code translate="no">. </code>It allows you to avoid unpleasant
                                            surprises.</p>
                                    </div>
                                </section>
                                <section data-type="sect3" data-pdf-bookmark="Additional optional parameters">
                                    <div class="sect3" id="ch02_additional_optional_parameters_1">
                                        <h3>Additional optional parameters</h3>
                                        <p>Also as with <code translate="no">openai.ChatCompletion</code>, additional optional
                                            parameters may be used to further tweak the behavior of the model. These
                                            parameters are the same as those used for
                                            <code translate="no">openai.ChatCompletion</code>, so we will not detail them again. <a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="temperature input parameter for chat completion"
                                                data-secondary="n parameter and" id="id687"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="n parameter for multiple chat completions"
                                                data-secondary="temperature and" id="id688"></a>Remember that you can
                                            control the output with the <code translate="no">temperature</code> or <code translate="no">n</code>
                                            parameter, control your costs with <code translate="no">max_tokens</code>, and use the
                                            <code translate="no">stream</code> option if you wish to have a better user experience with
                                            long completions.</p>
                                    </div>
                                </section>
                            </div>
                        </section>
                        <section data-type="sect2"
                            data-pdf-bookmark="Output Result Format for the Text Completion Endpoint">
                            <div class="sect2" id="output_result_format_for_the_text_completion_endpo">
                                <h2>Output Result Format for the Text Completion Endpoint</h2>
                                <p>Now that you have all the information<a contenteditable="false" data-type="indexterm"
                                        data-primary="text completion" data-secondary="output result format"
                                        id="id689"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="output result format" data-secondary="text completion endpoint"
                                        id="id690"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="created output parameter" data-secondary="text completion"
                                        id="id691"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="id output parameter" data-secondary="text completion"
                                        id="id692"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="model output parameter" data-secondary="text completion"
                                        id="id693"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="object output parameter" data-secondary="text completion"
                                        id="id694"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="usage output parameter" data-secondary="text completion"
                                        id="id695"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="choices output parameter" data-secondary="text completion"
                                        id="id696"></a> needed to query text-based models, you will find that the
                                    results are very similar to the chat endpoint results. Here is an example output for
                                    our “Hello World” example with the <code translate="no">davinci</code> model:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="p">{</code>
      <code translate="no" class="s2">"choices"</code><code translate="no" class="p">:</code> <code translate="no" class="p">[</code>
          <code translate="no" class="p">{</code>
              <code translate="no" class="s2">"finish_reason"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"stop"</code><code translate="no" class="p">,</code>
              <code translate="no" class="s2">"index"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">0</code><code translate="no" class="p">,</code>
              <code translate="no" class="s2">"logprobs"</code><code translate="no" class="p">:</code> <code translate="no" class="n">null</code><code translate="no" class="p">,</code>
              <code translate="no" class="s2">"text"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"&lt;br /&gt;</code><code translate="no" class="se">\n\n</code><code translate="no" class="s2">Hi there! It's great to see you."</code><code translate="no" class="p">,</code>
          <code translate="no" class="p">}</code>
      <code translate="no" class="p">],</code>
      <code translate="no" class="s2">"created"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">1681883111</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"id"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"cmpl-76uutuZiSxOyzaFboxBnaatGINMLT"</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"model"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"text-davinci-003"</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"object"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"text_completion"</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"usage"</code><code translate="no" class="p">:</code> <code translate="no" class="p">{</code><code translate="no" class="s2">"completion_tokens"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">15</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"prompt_tokens"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">3</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"total_tokens"</code><code translate="no" class="p">:</code> <code translate="no" class="mi">18</code><code translate="no" class="p">},</code>
  <code translate="no" class="p">}</code></pre>

                                <div data-type="note" epub:type="note">
                                    <h6>Note</h6>
                                    <p>This output is very similar to what we got with the chat models. The only
                                        difference is in the <code translate="no">choice</code> object: instead of having a message
                                        with <code translate="no">content</code> and <code translate="no">role</code> attributes, we have a simple
                                        <code translate="no">text</code> attribute containing the completion generated by the model.
                                    </p>
                                </div>
                            </div>
                        </section>
                    </div>
                </section>
                <section data-type="sect1" data-pdf-bookmark="Considerations">
                    <div class="sect1" id="considerations">
                        <h1>Considerations</h1>
                        <p>You should consider two important things before using the APIs extensively: cost and data
                            privacy.</p>
                        <section data-type="sect2" data-pdf-bookmark="Pricing and Token Limitations">
                            <div class="sect2" id="pricing_and_token_limitations">
                                <h2>Pricing and Token Limitations</h2>
                                <p>OpenAI keeps the pricing<a contenteditable="false" data-type="indexterm"
                                        data-primary="pricing OpenAI models" data-secondary="about"
                                        data-tertiary="pricing page link" id="id697"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="GPT models" data-secondary="pricing"
                                        data-tertiary="pricing page link" id="id698"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="pricing"
                                        data-tertiary="pricing page link" id="id699"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="GPT-3 (OpenAI)"
                                        data-secondary="pricing page link" id="id700"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="GPT-4 (OpenAI)" data-secondary="pricing"
                                        data-tertiary="pricing page link" id="id701"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="OpenAI" data-secondary="prices of models"
                                        data-tertiary="pricing page link" id="id702"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="resources online" data-secondary="OpenAI"
                                        data-tertiary="pricing page link" id="id703"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="ChatGPT (OpenAI)" data-secondary="pricing"
                                        data-tertiary="model comparison chart" id="id704"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="GPT models" data-secondary="pricing"
                                        data-tertiary="model comparison chart" id="id705"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="GPT-3 (OpenAI)"
                                        data-secondary="pricing page link" data-tertiary="model comparison chart"
                                        id="id706"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="GPT-4 (OpenAI)" data-secondary="pricing"
                                        data-tertiary="model comparison chart" id="id707"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="tokenization in GPT models"
                                        data-secondary="tokens" data-tertiary="model comparison chart" id="id708"></a>
                                    of its models listed on its <a href="https://openai.com/pricing">pricing page</a>.
                                    Note that OpenAI is not bound to maintain this pricing, and the costs may change
                                    over time.</p>
                                <p>At the time of this writing, the pricing is as shown in <a data-type="xref"
                                        href="#table-2-6">Table&nbsp;2-6</a> for the OpenAI models used most often.</p>
                                <table class="lines" id="table-2-6">
                                    <caption><span class="label">Table 2-6. </span>Pricing and token limitations per
                                        model</caption>
                                    <thead>
                                        <tr>
                                            <th>Family</th>
                                            <th>Model</th>
                                            <th>Pricing</th>
                                            <th>Max tokens</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>Chat</td>
                                            <td>
                                                <code translate="no">gpt-4</code>
                                            </td>
                                            <td>
                                                <p>Prompt: $0.03 per 1,000 tokens</p>
                                                <p>Completion: $0.06 per 1,000 tokens</p>
                                            </td>
                                            <td>8,192 </td>
                                        </tr>
                                        <tr>
                                            <td>Chat</td>
                                            <td>
                                                <code translate="no">gpt-4-32k</code>
                                            </td>
                                            <td>
                                                <p>Prompt: $0.06 per 1,000 tokens</p>
                                                <p> Completion: $0.012 per 1,000 tokens</p>
                                            </td>
                                            <td>32,768 </td>
                                        </tr>
                                        <tr>
                                            <td>Chat</td>
                                            <td>
                                                <code translate="no">gpt-3.5-turbo</code>
                                            </td>
                                            <td>
                                                <p>Prompt: $0.0015 per 1,000 tokens</p>
                                                <p> Completion: $0.002 per 1,000 tokens</p>
                                            </td>
                                            <td>4,096</td>
                                        </tr>
                                        <tr>
                                            <td>Chat</td>
                                            <td>
                                                <code translate="no">gpt-3.5-turbo-16k</code>
                                            </td>
                                            <td>
                                                <p>Prompt: $0.003 per 1,000 tokens</p>
                                                <p> Completion: $0.004 per 1,000 tokens</p>
                                            </td>
                                            <td>16,384</td>
                                        </tr>
                                        <tr>
                                            <td>Text completion</td>
                                            <td>
                                                <code translate="no">text-davinci-003</code>
                                            </td>
                                            <td>$0.02 per 1,000 tokens</td>
                                            <td>4,097</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <p>There are several things to note from <a data-type="xref"
                                        href="#table-2-6">Table&nbsp;2-6</a>:</p>
                                <p>The <code translate="no">davinci</code> model is more than 10 times the cost of the GPT-3.5 Turbo
                                    4,000-context model. Since <code translate="no">gpt-3.5-turbo</code> can also be used for
                                    single-turn completion tasks and since both models are nearly equal in accuracy for
                                    this type of task, it is recommended to use GPT-3.5 Turbo (unless you need special
                                    features such as <span class="keep-together">insertion,</span> via the parameter
                                    suffix, or if <code translate="no">text-davinci-003</code> outperforms <code translate="no">gpt-3.5-turbo</code>
                                    for your specific task).
                                </p>
                                <p>GPT-3.5 Turbo is less expensive than GPT-4. The differences between GPT-4 and GPT-3.5
                                    are irrelevant for many basic tasks. However, in complex inference situations, GPT-4
                                    far outperforms any previous model.</p>
                                <p>The chat models have a different pricing system than the <code translate="no">davinci</code> models:
                                    they differentiate input (prompt) and output (completion).</p>
                                <p>GPT-4 allows a context twice as long as GPT-3.5 Turbo, and can even go up to 32,000
                                    tokens, which is equivalent to more than 25,000 words of text. GPT-4 enables use
                                    cases such as long-form content creation, advanced conversation, and document search
                                    and analysis… for a cost.</p>
                            </div>
                        </section>
                        <section data-type="sect2" data-pdf-bookmark="Security and Privacy: Caution!">
                            <div class="sect2" id="security_and_privacy_caution">
                                <h2>Security and Privacy: Caution!</h2>
                                <p>As we write this, OpenAI claims<a contenteditable="false" data-type="indexterm"
                                        data-primary="security"
                                        data-secondary="customer data not used by OpenAI for training" id="id709"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="privacy of customer data" id="id710"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="training"
                                        data-secondary="customer data not used by OpenAI" id="id711"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="inputs retained by OpenAI" id="id712"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="APIs (application programming interfaces)"
                                        data-secondary="inputs retained by OpenAI" id="id713"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="OpenAI"
                                        data-secondary="usage policies" data-tertiary="data usage policy"
                                        id="id714"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="data usage policy of OpenAI" id="id715"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="usage policies of OpenAI" data-secondary="data usage policy"
                                        id="id716"></a> the data sent as input to the models will not be used for
                                    retraining unless you decide to opt in. However, your inputs are retained for 30
                                    days for monitoring and usage compliance-checking purposes. This means OpenAI
                                    employees as well as specialized third-party contractors may have access to your API
                                    data.</p>
                                <div data-type="warning" epub:type="warning">
                                    <h6>Warning</h6>
                                    <p>Never send sensitive data<a contenteditable="false" data-type="indexterm"
                                            data-primary="sensitive data caution" id="id717"></a><a
                                            contenteditable="false" data-type="indexterm"
                                            data-primary="data that is sensitive" id="id718"></a><a
                                            contenteditable="false" data-type="indexterm"
                                            data-primary="resources online" data-secondary="OpenAI"
                                            data-tertiary="data usage policy" id="id719"></a> such as personal
                                        information or passwords through the OpenAI endpoints. We recommend that you
                                        check <a href="https://openai.com/policies/api-data-usage-policies">OpenAI’s
                                            data usage policy</a> for the latest information, as this can be subject to
                                        change. If you are an international user, be aware that your personal
                                        information and the data you send as input can be transferred from your location
                                        to the OpenAI facilities and servers in the United States. This may have some
                                        legal impact on your application creation.</p>
                                </div>
                                <p>More details on how to build LLM-powered applications while taking into account
                                    security and privacy issues can be found in <a data-type="xref"
                                        href="ch03.html#building_apps_with_gpt_4_and_chatgpt">Chapter&nbsp;3</a>.</p>
                            </div>
                        </section>
                    </div>
                </section>
                <section data-type="sect1" data-pdf-bookmark="Other OpenAI APIs and Functionalities">
                    <div class="sect1" id="other_openai_apis_and_functionalities">
                        <h1>Other OpenAI APIs and Functionalities</h1>
                        <p>Your OpenAI account gives you access to functionalities besides text completion. <a
                                contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="API"
                                data-tertiary="reference page link" id="id720"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="APIs (application programming interfaces)"
                                data-secondary="OpenAI API" data-tertiary="reference page link" id="id721"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="OpenAI" data-secondary="API"
                                data-tertiary="additional functionalities" id="id722"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="APIs (application programming interfaces)"
                                data-secondary="OpenAI API" data-tertiary="additional functionalities" id="id723"></a><a
                                contenteditable="false" data-type="indexterm" data-primary="resources online"
                                data-secondary="OpenAI" data-tertiary="API reference page" id="id724"></a>We selected
                            several of these functionalities to explore in this section, but if you want a deep dive
                            into all the API possibilities, look at <a
                                href="https://platform.openai.com/docs/api-reference">OpenAI’s API reference page</a>.
                        </p>
                        <section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Embeddings">
                            <div class="sect2" id="ch02-embeddings">
                                <h2 class="less_space">Embeddings</h2>
                                <p>Since a model relies on mathematical functions,<a contenteditable="false"
                                        data-type="indexterm" data-primary="embeddings" id="ch02emb"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="tokenization in GPT models" data-secondary="tokens"
                                        data-tertiary="embeddings converting to numerical" id="ch02emb2"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="words converted to numericals via embeddings" id="ch02emb3"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="embeddings"
                                        data-secondary="about" id="id725"></a> it needs numerical input to process
                                    information. However, many elements, such as words and tokens, aren’t inherently
                                    numerical. To overcome this, <em>embeddings</em> convert these concepts into
                                    numerical vectors. Embeddings allow computers to process the relationships between
                                    these concepts more efficiently by representing them numerically. In some
                                    situations, it can be useful to have access to embeddings, and OpenAI provides a
                                    model that can transform a text into a vector of numbers. The embeddings endpoint
                                    allows developers to obtain a vector representation of an input text. This vector
                                    representation can then be used as input to other ML models and NLP algorithms.</p>
                                <p>At the time of this writing,<a contenteditable="false" data-type="indexterm"
                                        data-primary="text-embedding-ada-002 model recommended" id="id726"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="embeddings"
                                        data-secondary="text-embedding-ada-002 model recommended" id="id727"></a> OpenAI
                                    recommends using its latest model, <code translate="no">text-embedding-ada-002</code>, for nearly
                                    all use cases. It is very simple to use:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="n">result</code> <code translate="no" class="o">=</code> <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">Embedding</code><code translate="no" class="o">.</code><code translate="no" class="n">create</code><code translate="no" class="p">(</code>
      <code translate="no" class="n">model</code><code translate="no" class="o">=</code><code translate="no" class="s2">"text-embedding-ada-002"</code><code translate="no" class="p">,</code> <code translate="no" class="nb">input</code><code translate="no" class="o">=</code><code translate="no" class="s2">"your text"</code>
  <code translate="no" class="p">)</code></pre>

                                <p>The embedding is accessed with:</p>

                                <pre translate="no" data-type="programlisting"
                                    data-code-language="python"><code translate="no" class="n">result</code><code translate="no" class="p">[</code><code translate="no" class="s1">'data'</code><code translate="no" class="p">][</code><code translate="no" class="s1">'embedding'</code><code translate="no" class="p">]</code></pre>

                                <p>The resulting embedding is a vector: an array of floats.</p>
                                <div data-type="tip">
                                    <h6>Tip</h6>
                                    <p>The complete documentation<a contenteditable="false" data-type="indexterm"
                                            data-primary="embeddings" data-secondary="documentation link"
                                            id="id728"></a><a contenteditable="false" data-type="indexterm"
                                            data-primary="resources online" data-secondary="OpenAI"
                                            data-tertiary="embeddings documentation" id="id729"></a> on embeddings is
                                        available in <a
                                            href="https://platform.openai.com/docs/api-reference/embeddings">OpenAI’s
                                            reference documents</a>. </p>
                                </div>
                                <p>The principle of embeddings is to represent text strings meaningfully in some space
                                    that captures their semantic similarity. With this idea, you can have various use
                                    cases:</p>
                                <dl>
                                    <dt>Search </dt>
                                    <dd>
                                        <p>Sort results by relevance to the query string.</p>
                                    </dd>
                                    <dt>Recommendations </dt>
                                    <dd>
                                        <p>Recommend articles that contain text strings related to the query string.</p>
                                    </dd>
                                    <dt>Clustering </dt>
                                    <dd>
                                        <p>Group strings by similarity.</p>
                                    </dd>
                                    <dt>Anomaly detection </dt>
                                    <dd>
                                        <p>Find a text string that is not related to the other strings.</p>
                                    </dd>
                                </dl>
                                <aside data-type="sidebar" epub:type="sidebar">
                                    <div class="sidebar" id="id730">
                                        <h1>How Embeddings Translate Language for Machine Learning</h1>
                                        <p>In the world of ML, especially<a contenteditable="false"
                                                data-type="indexterm" data-primary="embeddings"
                                                data-secondary="translated to machine learning" id="id731"></a> when
                                            dealing with language models, we encounter an important concept called
                                            <em>embeddings</em>. Embeddings transform categorical data—such as tokens,
                                            typically single words or groups of these tokens that form sentences—into a
                                            numerical format, specifically vectors of real numbers. This transformation
                                            is essential because ML models rely on numerical data and aren’t ideally
                                            equipped to process categorical data directly.</p>
                                        <p>To visualize this, think of embeddings as a sophisticated language
                                            interpreter that translates the rich world of words and sentences into the
                                            universal language of numbers that ML models understand fluently. <a
                                                contenteditable="false" data-type="indexterm" data-primary="embeddings"
                                                data-secondary="translated to machine learning"
                                                data-tertiary="semantic similarity" id="id732"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="semantic similarity preserved by embeddings"
                                                id="id733"></a>A truly remarkable feature of embeddings is their ability
                                            to preserve <em>semantic similarity</em>, meaning that words or phrases with
                                            similar meanings tend to be mapped closer together in numerical space.</p>
                                        <p>This property is fundamental in<a contenteditable="false"
                                                data-type="indexterm" data-primary="embeddings"
                                                data-secondary="translated to machine learning"
                                                data-tertiary="information retrieval" id="id734"></a><a
                                                contenteditable="false" data-type="indexterm"
                                                data-primary="information retrieval" data-secondary="embeddings"
                                                id="id735"></a> a process called <em>information retrieval</em>, which
                                            involves extracting relevant information from a large dataset. Given the way
                                            embeddings inherently capture similarities, they are an excellent tool for
                                            such operations.</p>
                                        <p>Modern LLMs make extensive use of embeddings. Typically, these models deal
                                            with embeddings of about 512 dimensions, providing a high-dimension
                                            numerical representation of the language data. The depth of these dimensions
                                            allows the models to distinguish a wide range of complex patterns. As a
                                            result, they perform remarkably well in various language tasks, ranging from
                                            translation and summarization to generating text responses that convincingly
                                            resemble human discourse.</p>
                                    </div>
                                </aside>
                                <p>Embeddings have the property that if two texts have a similar meaning, their vector
                                    representation will be similar. As an example, in <a data-type="xref"
                                        href="#fig_8_example_of_two_dimensional_embedding_of_three_sent">Figure&nbsp;2-8</a>,
                                    three sentences are shown in two-dimensional embeddings. Although the two sentences
                                    “The cat chased the mouse around the house.” and “Around the house, the mouse was
                                    pursued by the cat.” have different syntaxes, they convey the same general meaning,
                                    and therefore they should have similar embedding representations. As the sentence
                                    “The astronaut repaired the spaceship in orbit.” is unrelated to the topic of the
                                    previous sentences (cats and mice) and discusses an entirely different subject
                                    (astronauts and spaceships), it should have a significantly different embedding
                                    representation. Note that in this example, for clarity we show the embedding as
                                    having two dimensions, but in reality, they are often in a much higher dimension,
                                    such as 512.</p>
                                <figure>
                                    <div id="fig_8_example_of_two_dimensional_embedding_of_three_sent" class="figure">
                                        <img src="/api/v2/epubs/urn:orm:book:9781098152475/files/assets/dagc_0208.png"
                                            alt="" width="600" height="396">
                                        <h6><span class="label">Figure 2-8. </span>Example of two-dimensional embedding
                                            of three sentences</h6>
                                    </div>
                                </figure>
                                <p>We refer to the embeddings API several times in the remaining chapters, as embeddings
                                    are an essential part of processing natural language with AI models.<a
                                        contenteditable="false" data-type="indexterm" data-primary=""
                                        data-startref="ch02emb" id="id736"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="" data-startref="ch02emb2" id="id737"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary=""
                                        data-startref="ch02emb3" id="id738"></a></p>
                            </div>
                        </section>
                        <section data-type="sect2" data-pdf-bookmark="Moderation Model">
                            <div class="sect2" id="moderation_model">
                                <h2>Moderation Model</h2>
                                <p>As mentioned earlier, when using<a contenteditable="false" data-type="indexterm"
                                        data-primary="OpenAI" data-secondary="usage policies"
                                        data-tertiary="compliance model" id="id739"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="usage policies of OpenAI"
                                        data-secondary="compliance model" id="id740"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="OpenAI" data-secondary="usage policies"
                                        data-tertiary="link" id="id741"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="usage policies of OpenAI"
                                        data-secondary="link" id="id742"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="resources online" data-secondary="OpenAI"
                                        data-tertiary="usage policies" id="id743"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="GPT models"
                                        data-secondary="OpenAI usage policy compliance" id="id744"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="GPT models"
                                        data-secondary="OpenAI usage policy compliance"
                                        data-tertiary="link to usage policies" id="id745"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="moderation model" id="ch02-modmod"></a> the
                                    OpenAI models you must respect the rules described in the <a
                                        href="https://openai.com/policies/usage-policies">OpenAI usage policies</a>. To
                                    help you respect these rules, OpenAI provides a model to check whether the content
                                    complies with these usage policies. This can be useful if you build an app in which
                                    user input will be used as a prompt: you can filter the queries based on the
                                    moderation endpoint results. The model provides classification capabilities that
                                    allow you to search for content in the following categories:<a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="hate categories of moderation model" id="id746"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="sexual categories of moderation model" id="id747"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="self-harm category of moderation model" id="id748"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="violence categories of moderation model" id="id749"></a> </p>
                                <dl>
                                    <dt>Hate </dt>
                                    <dd>
                                        <p>Promoting hatred against groups based on race, gender, ethnicity, religion,
                                            nationality, sexual orientation, disability, or caste</p>
                                    </dd>
                                    <dt>Hate/threatening </dt>
                                    <dd>
                                        <p>Hateful content that involves violence or severe harm to targeted groups</p>
                                    </dd>
                                    <dt>Self-harm </dt>
                                    <dd>
                                        <p>Content that promotes or depicts acts of self-harm, including suicide,
                                            cutting, and eating disorders</p>
                                    </dd>
                                    <dt>Sexual </dt>
                                    <dd>
                                        <p>Content designed to describe a sexual activity or promote sexual services
                                            (except for education and wellness)</p>
                                    </dd>
                                    <dt>Sexual with minors </dt>
                                    <dd>
                                        <p>Sexually explicit content involving persons under 18 years of age</p>
                                    </dd>
                                    <dt>Violence </dt>
                                    <dd>
                                        <p>Content that glorifies violence or celebrates the suffering or humiliation of
                                            others</p>
                                    </dd>
                                    <dt>Violence/graphic </dt>
                                    <dd>
                                        <p>Violent content depicting death, violence, or serious bodily injury in
                                            graphic detail</p>
                                    </dd>
                                </dl>
                                <div data-type="note" epub:type="note">
                                    <h6>Note</h6>
                                    <p>Support for languages other than English is limited.</p>
                                </div>
                                <p>The endpoint for the moderation<a contenteditable="false" data-type="indexterm"
                                        data-primary="openai.Moderation.create()" id="id750"></a> model is
                                    <code translate="no">openai.Moderation.create</code>, and only two parameters are available: the
                                    model and the input text. <a contenteditable="false" data-type="indexterm"
                                        data-primary="text-moderation-latest" id="id751"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="text-moderation-stable" id="id752"></a>There
                                    are two models of content moderation. The default is
                                    <code translate="no">text-moderation-latest</code>, which is automatically updated over time to
                                    ensure that you always use the most accurate model. The other model is
                                    <code translate="no">text-moderation-stable</code>. OpenAI will notify you before updating this
                                    model. </p>
                                <div data-type="warning" epub:type="warning">
                                    <h6>Warning</h6>
                                    <p>The accuracy of <code translate="no">text-moderation-stable</code> may be slightly lower than
                                        <code translate="no">text-moderation-latest</code>. </p>
                                </div>
                                <p>Here is an example of how to use this moderation model:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="kn">import</code> <code translate="no" class="nn">openai</code>
  <code translate="no" class="c1"># Call the openai Moderation endpoint, with the text-moderation-latest model</code>
  <code translate="no" class="n">response</code> <code translate="no" class="o">=</code> <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">Moderation</code><code translate="no" class="o">.</code><code translate="no" class="n">create</code><code translate="no" class="p">(</code>
      <code translate="no" class="n">model</code><code translate="no" class="o">=</code><code translate="no" class="s2">"text-moderation-latest"</code><code translate="no" class="p">,</code>
      <code translate="no" class="nb">input</code><code translate="no" class="o">=</code><code translate="no" class="s2">"I want to kill my neighbor."</code><code translate="no" class="p">,</code>
  <code translate="no" class="p">)</code></pre>

                                <p>Let’s take a look at the output result of the moderation endpoint contained in the
                                    <code translate="no">response</code> object:</p>

                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="p">{</code>
      <code translate="no" class="s2">"id"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"modr-7AftIJg7L5jqGIsbc7NutObH4j0Ig"</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"model"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"text-moderation-004"</code><code translate="no" class="p">,</code>
      <code translate="no" class="s2">"results"</code><code translate="no" class="p">:</code> <code translate="no" class="p">[</code>
          <code translate="no" class="p">{</code>
              <code translate="no" class="s2">"categories"</code><code translate="no" class="p">:</code> <code translate="no" class="p">{</code>
                  <code translate="no" class="s2">"hate"</code><code translate="no" class="p">:</code> <code translate="no" class="n">false</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"hate/threatening"</code><code translate="no" class="p">:</code> <code translate="no" class="n">false</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"self-harm"</code><code translate="no" class="p">:</code> <code translate="no" class="n">false</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"sexual"</code><code translate="no" class="p">:</code> <code translate="no" class="n">false</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"sexual/minors"</code><code translate="no" class="p">:</code> <code translate="no" class="n">false</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"violence"</code><code translate="no" class="p">:</code> <code translate="no" class="n">true</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"violence/graphic"</code><code translate="no" class="p">:</code> <code translate="no" class="n">false</code><code translate="no" class="p">,</code>
              <code translate="no" class="p">},</code>
              <code translate="no" class="s2">"category_scores"</code><code translate="no" class="p">:</code> <code translate="no" class="p">{</code>
                  <code translate="no" class="s2">"hate"</code><code translate="no" class="p">:</code> <code translate="no" class="mf">0.0400671623647213</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"hate/threatening"</code><code translate="no" class="p">:</code> <code translate="no" class="mf">3.671687863970874e-06</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"self-harm"</code><code translate="no" class="p">:</code> <code translate="no" class="mf">1.3143378509994363e-06</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"sexual"</code><code translate="no" class="p">:</code> <code translate="no" class="mf">5.508050548996835e-07</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"sexual/minors"</code><code translate="no" class="p">:</code> <code translate="no" class="mf">1.1862029225540027e-07</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"violence"</code><code translate="no" class="p">:</code> <code translate="no" class="mf">0.9461417198181152</code><code translate="no" class="p">,</code>
                  <code translate="no" class="s2">"violence/graphic"</code><code translate="no" class="p">:</code> <code translate="no" class="mf">1.463699845771771e-06</code><code translate="no" class="p">,</code>
              <code translate="no" class="p">},</code>
              <code translate="no" class="s2">"flagged"</code><code translate="no" class="p">:</code> <code translate="no" class="n">true</code><code translate="no" class="p">,</code>
          <code translate="no" class="p">}</code>
      <code translate="no" class="p">],</code>
  <code translate="no" class="p">}</code></pre>

                                <p>The output result of the moderation endpoint provides the pieces of information shown
                                    in <a data-type="xref" href="#table-2-7">Table&nbsp;2-7</a>.</p>
                                <table class="lines" id="table-2-7">
                                    <caption><span class="label">Table 2-7. </span>Description of the output of the
                                        moderation endpoint</caption>
                                    <thead>
                                        <tr>
                                            <th>Field name</th>
                                            <th>Type</th>
                                            <th>Description</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>
                                                <code translate="no">model</code>
                                            </td>
                                            <td>String</td>
                                            <td>This is the model used for the prediction. When calling the method in
                                                our earlier example, we specified the use of the model
                                                <code translate="no">text-moderation-latest</code>, and in the output result, the model
                                                used is <code translate="no">text-moderation-004</code>. If we had called the method
                                                with <code translate="no">text-moderation-stable</code>, then
                                                <code translate="no">text-moderation-001</code> would have been used.</td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <code translate="no">flagged</code>
                                            </td>
                                            <td>Boolean</td>
                                            <td>If the model identifies the content as violating OpenAI’s usage
                                                policies, set this to <code translate="no">true</code>; otherwise, set it to
                                                <code translate="no">false</code>.</td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <code translate="no">categories</code>
                                            </td>
                                            <td>Dict</td>
                                            <td>This includes a dictionary with binary flags for policy violation
                                                categories. For each category, the value is <code translate="no">true</code> if the
                                                model identifies a violation and <code translate="no">false</code> if not. The
                                                dictionary can be accessed via
                                                <code translate="no">print(type(response['results'][0]​['cate⁠gories']))</code>.</td>
                                        </tr>
                                        <tr>
                                            <td>
                                                <span class="keep-together"><code translate="no">category_scores</code></span>
                                            </td>
                                            <td>Dict</td>
                                            <td>The model provides a dictionary with category-specific scores that show
                                                how confident it is that the input goes against OpenAI’s policy for that
                                                category. Scores range from 0 to 1, with higher scores meaning more
                                                confidence. These scores should not be seen as probabilities. The
                                                dictionary can be accessed via
                                                <code translate="no">print(type(response​['re⁠sults'][0]['category_scores']))</code>.
                                            </td>
                                        </tr>
                                    </tbody>
                                </table>
                                <div data-type="warning" epub:type="warning">
                                    <h6>Warning</h6>
                                    <p>OpenAI will regularly improve the moderation system. As a result, the
                                        <code translate="no">category_scores</code> may vary, and the threshold set to determine the
                                        category value from a category score may also change. </p>
                                </div>
                            </div>
                        </section>
                        <section data-type="sect2" data-pdf-bookmark="Whisper and DALL-E">
                            <div class="sect2" id="whisper_and_dall_e">
                                <h2>Whisper and DALL-E</h2>
                                <p>OpenAI also provides other AI tools that are not LLMs but can easily be used in
                                    combination with GPT models in some use cases. We don’t explain them here because
                                    they are not the focus of this book. But don’t worry, using their APIs is very
                                    similar to using OpenAI’s LLM APIs.</p>
                                <p>Whisper is a versatile model<a contenteditable="false" data-type="indexterm"
                                        data-primary="Whisper (OpenAI) speech recognition model" id="id753"></a><a
                                        contenteditable="false" data-type="indexterm"
                                        data-primary="speech recognition model Whisper" id="id754"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="OpenAI"
                                        data-secondary="Whisper speech recognition model" id="id755"></a> for speech
                                    recognition. It is trained on a large audio dataset and is also a multitasking model
                                    that can perform multilingual speech recognition, speech translation, and language
                                    identification. <a contenteditable="false" data-type="indexterm"
                                        data-primary="GitHub" data-secondary="Whisper open source code"
                                        id="id756"></a><a contenteditable="false" data-type="indexterm"
                                        data-primary="resources online" data-secondary="OpenAI"
                                        data-tertiary="Whisper open source code" id="id757"></a>An open source version
                                    is available on the <a href="https://github.com/openai/whisper">Whisper project’s
                                        GitHub page</a> of OpenAI. </p>
                                <p>In January 2021, OpenAI introduced<a contenteditable="false" data-type="indexterm"
                                        data-primary="DALL-E AI system (OpenAI)" id="id758"></a><a
                                        contenteditable="false" data-type="indexterm" data-primary="OpenAI"
                                        data-secondary="DALL-E AI system" id="id759"></a><a contenteditable="false"
                                        data-type="indexterm" data-primary="resources online" data-secondary="OpenAI"
                                        data-tertiary="DALL-E AI system to try" id="id760"></a> DALL-E, an AI system
                                    capable of creating realistic images and artwork from natural language descriptions.
                                    DALL-E 2 takes the technology further with higher resolution, greater input text
                                    comprehension, and new capabilities. Both versions of DALL-E were created by
                                    training a transformer model on images and their text descriptions. You can try
                                    DALL-E 2 through the API and via the <a href="https://labs.openai.com">Labs
                                        interface</a>.<a contenteditable="false" data-type="indexterm" data-primary=""
                                        data-startref="ch02-modmod" id="id761"></a></p>
                            </div>
                        </section>
                    </div>
                </section>
                <section data-type="sect1" data-pdf-bookmark="Summary (and Cheat Sheet)">
                    <div class="sect1" id="summary_and_cheat_sheet">
                        <h1>Summary (and Cheat Sheet)</h1>
                        <p>As we have seen, OpenAI provides its models as a service, through an API. In this book, we
                            chose to use the Python library provided by OpenAI, which is a simple wrapper around the
                            API. With this library, we can interact with the GPT-4 and ChatGPT models: the first step to
                            building LLM-powered applications! However, using these models implies several
                            considerations: API key management, pricing, and privacy. </p>
                        <p>Before starting, we recommend looking at the OpenAI usage policies, and playing with the
                            Playground to get familiar with the different models without the hassle of coding. Remember:
                            GPT-3.5 Turbo, the model behind ChatGPT, is the best choice for most use cases.</p>
                        <p>Following is a cheat sheet to use when sending input to GPT-3.5 Turbo:<a
                                contenteditable="false" data-type="indexterm" data-primary="GPT-3.5 (OpenAI)"
                                data-secondary="cheat sheet for input" id="id762"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="input parameters"
                                data-secondary="cheat sheet for GPT-3.5 Turbo" id="id763"></a><a contenteditable="false"
                                data-type="indexterm" data-primary="ChatGPT (OpenAI)"
                                data-secondary="using with OpenAI Python library" data-tertiary="cheat sheet for input"
                                id="id764"></a><a contenteditable="false" data-type="indexterm" data-primary="pip"
                                data-secondary="installing openai" id="id765"></a></p>
                        <ol>
                            <li>
                                <p>Install the <code translate="no">openai</code> dependency:</p>
                                <pre translate="no" data-type="programlisting">pip install openai</pre>
                            </li>
                            <li>
                                <p>Set your API key as an environment variable:</p>
                                <pre translate="no" data-type="programlisting">export OPENAI_API_KEY=sk-(...)</pre>
                            </li>
                            <li>
                                <p>In Python, import <code translate="no">openai</code>:</p>
                                <pre translate="no" data-type="programlisting"
                                    data-code-language="python"><code translate="no" class="kn">import</code> <code translate="no" class="nn">openai</code></pre>
                            </li>
                            <li class="pagebreak-before less_space">
                                <p>Call the <code translate="no">openai.ChatCompletion</code> endpoint:</p>
                                <pre translate="no" data-type="programlisting" data-code-language="python"><code translate="no" class="n">response</code> <code translate="no" class="o">=</code> <code translate="no" class="n">openai</code><code translate="no" class="o">.</code><code translate="no" class="n">ChatCompletion</code><code translate="no" class="o">.</code><code translate="no" class="n">create</code><code translate="no" class="p">(</code>
      <code translate="no" class="n">model</code><code translate="no" class="o">=</code><code translate="no" class="s2">"gpt-3.5-turbo"</code><code translate="no" class="p">,</code>
      <code translate="no" class="n">messages</code><code translate="no" class="o">=</code><code translate="no" class="p">[{</code><code translate="no" class="s2">"role"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"user"</code><code translate="no" class="p">,</code> <code translate="no" class="s2">"content"</code><code translate="no" class="p">:</code> <code translate="no" class="s2">"Your Input Here"</code><code translate="no" class="p">}],</code>
  <code translate="no" class="p">)</code></pre>
                            </li>
                            <li>
                                <p>Get the answer:</p>
                                <pre translate="no" data-type="programlisting"
                                    data-code-language="python">    <code translate="no" class="nb">print</code><code translate="no" class="p">(</code><code translate="no" class="n">response</code><code translate="no" class="p">[</code><code translate="no" class="s1">'choices'</code><code translate="no" class="p">][</code><code translate="no" class="mi">0</code><code translate="no" class="p">][</code><code translate="no" class="s1">'message'</code><code translate="no" class="p">][</code><code translate="no" class="s1">'content'</code><code translate="no" class="p">])</code></pre>
                            </li>
                        </ol>
                        <div data-type="tip">
                            <h6>Tip</h6>
                            <p>Don’t forget to check the <a href="https://openai.com/pricing">pricing page</a>, and use
                                <a href="https://github.com/openai/tiktoken">tiktoken</a> to estimate the usage costs.
                            </p>
                        </div>
                        <p>Note that you should never send sensitive data, such as personal information or passwords,
                            through the OpenAI endpoints.</p>
                        <p>OpenAI also provides several other models and tools. You will find in the next chapters that
                            the embeddings endpoint is very useful for including NLP features in your application.</p>
                        <p>Now that you know <em>how</em> to use the OpenAI services, it’s time to dive into
                            <em>why</em> you should use them. In the next chapter, you’ll see an overview of various
                            examples and use cases to help you make the most out of the OpenAI ChatGPT and GPT-4 models.
                        </p>
                    </div>
                </section>
            </div>
        </section>
    </div>
</div>

</html>